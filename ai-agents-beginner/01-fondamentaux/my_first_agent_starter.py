#!/usr/bin/env python3
"""
ğŸ¯ Premier Agent IA - Assistant Personnel Intelligent
===================================================

VOTRE MISSION: CrÃ©er un assistant IA fonctionnel en 2h qui peut :
ğŸ’¬ Converser naturellement (comme ChatGPT)
ğŸ”§ Utiliser des outils (calculatrice, recherche, mÃ©tÃ©o)  
ğŸ‘¤ Demander validation humaine (pour contenus sensibles)
ğŸ§  Choisir automatiquement le bon comportement

EXEMPLES DE CE QUE VOTRE AGENT FERA:
ğŸ‘¤ "Salut !" â†’ ğŸ¤– [Chat] "Bonjour ! Comment puis-je vous aider ?"
ğŸ‘¤ "15 Ã— 8 + 42 ?" â†’ ğŸ¤– [Outil] ğŸ”§ "Le rÃ©sultat est 162"  
ğŸ‘¤ "DÃ©cision financiÃ¨re" â†’ ğŸ¤– [Validation] ğŸš¨ "Approbation requise"

INSTRUCTIONS:
- Suivez les 8 TODOs dans l'ordre (1â†’2â†’3â†’...â†’8)
- DÃ©commentez et complÃ©tez le code Ã  chaque Ã©tape
- Testez aprÃ¨s chaque TODO pour voir les progrÃ¨s
- Consultez STEP_BY_STEP_GUIDE.md pour les explications dÃ©taillÃ©es

â±ï¸ DurÃ©e: 68 minutes | ğŸ”‘ PrÃ©requis: ClÃ© OpenAI dans .env
"""

# TODO 1: Installation et Imports (3 min)
# DÃ©commentez les imports suivants et installez les dÃ©pendances
# pip install openai python-dotenv requests beautifulsoup4

import os
import json
import asyncio
from datetime import datetime
from dataclasses import dataclass, field
from typing import Dict, Any, List, Optional
from dotenv import load_dotenv

# TODO: DÃ©commentez les imports OpenAI
# from openai import OpenAI

# Charger les variables d'environnement
load_dotenv()

print("ğŸš€ Initialisation du Premier Agent IA")
print("ğŸ“ Module 1: Fondamentaux des Agents IA")
print("=" * 60)

# TODO 2: Architecture de Base (5 min)
# ComplÃ©tez les classes de base pour votre agent

@dataclass
class AgentState:
    """Ã‰tat de l'agent entre les interactions"""
    conversation_history: List[Dict[str, Any]] = field(default_factory=list)
    tools_used: List[str] = field(default_factory=list)
    user_preferences: Dict[str, Any] = field(default_factory=dict)
    session_id: str = ""
    total_interactions: int = 0
    
    def __post_init__(self):
        if not self.user_preferences:
            self.user_preferences = {"language": "fr", "style": "friendly"}
        if not self.session_id:
            self.session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

class BaseAgent:
    """Agent IA suivant la boucle Perception â†’ Plan â†’ Act â†’ Reflect"""
    
    def __init__(self):
        # TODO: Initialisez votre client OpenAI
        # api_key = os.getenv("OPENAI_API_KEY")
        # if not api_key:
        #     raise ValueError("âŒ OPENAI_API_KEY non trouvÃ©e ! CrÃ©ez un fichier .env")
        # self.client = OpenAI(api_key=api_key)
        
        self.client = None  # TODO: Remplacez par l'initialisation OpenAI
        
        self.state = AgentState()
        self.available_tools = {}  # Sera peuplÃ© dans TODO 5
        
        print(f"ğŸ¤– Agent initialisÃ© - Session: {self.state.session_id}")
    
    def perceive(self, user_input: str) -> Dict[str, Any]:
        """Ã‰tape 1: Analyser l'input et le contexte"""
        perception = {
            "user_input": user_input,
            "timestamp": datetime.now().isoformat(),
            "input_length": len(user_input.split()),
            "intent": self._analyze_intent(user_input),
            "context": self._get_relevant_context(),
            "complexity": self._assess_complexity(user_input)
        }
        
        print(f"ğŸ” PERCEPTION: {perception['intent']} (complexitÃ©: {perception['complexity']})")
        return perception
    
    def plan(self, perception: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Ã‰tape 2: CrÃ©er un plan d'action"""
        plan = []
        
        # TODO: ComplÃ©tez la logique de planification basÃ©e sur l'intent
        intent = perception["intent"]
        
        if intent == "calculation":
            plan.append({"action": "use_tool", "tool": "calculator", "priority": 1})
        elif intent == "information":
            plan.append({"action": "search_web", "tool": "web_search", "priority": 1})
        elif intent == "conversation":
            plan.append({"action": "llm_response", "tool": "direct_llm", "priority": 1})
        elif intent == "validation":
            plan.append({"action": "human_input", "tool": "human_loop", "priority": 1})
        
        # Toujours inclure une Ã©tape de rÃ©flexion
        plan.append({"action": "reflect", "tool": "self_assessment", "priority": 2})
        
        print(f"ğŸ“‹ PLAN: {len(plan)} Ã©tapes planifiÃ©es")
        return plan
    
    def act(self, plan: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Ã‰tape 3: ExÃ©cuter les actions planifiÃ©es"""
        results = []
        
        for step in sorted(plan, key=lambda x: x["priority"]):
            print(f"âš¡ EXÃ‰CUTION: {step['action']} avec {step['tool']}")
            
            # TODO: ImplÃ©mentez l'exÃ©cution des actions
            if step["action"] == "use_tool":
                result = self._execute_tool(step["tool"], step.get("params", {}))
            elif step["action"] == "llm_response":
                result = self._call_llm(step.get("prompt", ""))
            elif step["action"] == "human_input":
                result = self._request_human_input(step.get("question", ""))
            elif step["action"] == "reflect":
                result = self._self_reflect(results)
            else:
                result = {"error": f"Action inconnue: {step['action']}"}
            
            results.append({
                "step": step,
                "result": result,
                "timestamp": datetime.now().isoformat()
            })
        
        return results
    
    def reflect(self, results: List[Dict[str, Any]], expected_outcome: str = "") -> Dict[str, Any]:
        """Ã‰tape 4: Ã‰valuer les rÃ©sultats et s'amÃ©liorer"""
        reflection = {
            "success": all(r.get("result", {}).get("error") is None for r in results),
            "quality_score": self._assess_quality(results),
            "lessons_learned": [],
            "improvements": [],
            "user_satisfaction": None
        }
        
        # TODO: ComplÃ©tez la logique de rÃ©flexion
        for result in results:
            if "error" in result.get("result", {}):
                reflection["lessons_learned"].append(f"Erreur avec {result['step']['tool']}")
                reflection["improvements"].append(f"AmÃ©liorer {result['step']['action']}")
        
        # MÃ©moriser pour futures interactions
        self.state.conversation_history.append({
            "perception": results[0].get("perception", {}),
            "plan": [r["step"] for r in results],
            "results": [r["result"] for r in results],
            "reflection": reflection,
            "timestamp": datetime.now().isoformat()
        })
        
        print(f"ğŸ¤” RÃ‰FLEXION: SuccÃ¨s={reflection['success']}, QualitÃ©={reflection['quality_score']:.2f}")
        return reflection
    
    def _analyze_intent(self, user_input: str) -> str:
        """Analyser l'intention de l'utilisateur"""
        user_lower = user_input.lower()
        
        # TODO: AmÃ©liorez la dÃ©tection d'intent
        if any(word in user_lower for word in ["calcul", "addition", "multiplication", "combien"]):
            return "calculation"
        elif any(word in user_lower for word in ["recherche", "trouve", "information", "qu'est-ce"]):
            return "information"
        elif any(word in user_lower for word in ["valide", "vÃ©rifie", "confirme", "approuve"]):
            return "validation"
        else:
            return "conversation"
    
    def _get_relevant_context(self) -> Dict[str, Any]:
        """RÃ©cupÃ©rer le contexte pertinent"""
        recent_history = self.state.conversation_history[-3:] if self.state.conversation_history else []
        return {
            "recent_interactions": len(recent_history),
            "tools_previously_used": list(set(self.state.tools_used[-5:])),
            "user_preferences": self.state.user_preferences
        }
    
    def _assess_complexity(self, user_input: str) -> str:
        """Ã‰valuer la complexitÃ© de la demande"""
        complexity_indicators = len([
            word for word in user_input.lower().split() 
            if word in ["et", "puis", "ensuite", "aussi", "Ã©galement", "aprÃ¨s", "avant"]
        ])
        
        if complexity_indicators >= 2:
            return "high"
        elif complexity_indicators == 1:
            return "medium"
        else:
            return "low"
    
    def _assess_quality(self, results: List[Dict]) -> float:
        """Ã‰valuer la qualitÃ© des rÃ©sultats"""
        if not results:
            return 0.0
        
        successful_results = sum(1 for r in results if not r.get("result", {}).get("error"))
        return successful_results / len(results)
    
    def _execute_tool(self, tool_name: str, params: Dict) -> Dict[str, Any]:
        """ExÃ©cuter un outil - sera implÃ©mentÃ© dans TODO 5"""
        return {"error": "Outils pas encore implÃ©mentÃ©s", "tool": tool_name}
    
    def _call_llm(self, prompt: str) -> Dict[str, Any]:
        """Appeler le LLM - sera implÃ©mentÃ© dans TODO 3"""
        return {"error": "LLM pas encore configurÃ©", "prompt": prompt}
    
    def _request_human_input(self, question: str) -> Dict[str, Any]:
        """Demander une validation humaine - sera implÃ©mentÃ© dans TODO 6"""
        return {"error": "Validation humaine pas encore implÃ©mentÃ©e", "question": question}
    
    def _self_reflect(self, results: List[Dict]) -> Dict[str, Any]:
        """Auto-rÃ©flexion sur les rÃ©sultats"""
        return {"reflection": "Auto-rÃ©flexion basique", "results_count": len(results)}

# TODO 3: Configuration LLM (5 min)
# ComplÃ©tez l'intÃ©gration OpenAI

def setup_llm_integration(agent: BaseAgent):
    """Configurer l'intÃ©gration LLM"""
    print("\nğŸ¤– Ã‰TAPE: Configuration LLM")
    print("=" * 60)
    
    # TODO: DÃ©commentez et complÃ©tez la configuration OpenAI
    # try:
    #     api_key = os.getenv("OPENAI_API_KEY")
    #     if not api_key:
    #         raise ValueError("âŒ OPENAI_API_KEY non trouvÃ©e !")
    #     
    #     agent.client = OpenAI(api_key=api_key)
    #     agent.llm_config = {
    #         "model": "gpt-4",
    #         "temperature": 0.7,
    #         "max_tokens": 500
    #     }
    #     
    #     print("âœ… Client OpenAI configurÃ©")
    #     print(f"ğŸ¯ ModÃ¨le: {agent.llm_config['model']}")
    #     return True
    # except Exception as e:
    #     print(f"âŒ Erreur configuration LLM: {e}")
    #     return False
    
    print("âš ï¸ TODO 3: ImplÃ©mentez la configuration LLM")
    return False

def implement_llm_call(agent: BaseAgent):
    """ImplÃ©menter l'appel LLM"""
    
    def _call_llm(prompt: str, system_message: str = "") -> Dict[str, Any]:
        """Appeler le LLM avec gestion d'erreurs"""
        # TODO: DÃ©commentez et complÃ©tez l'appel OpenAI
        # try:
        #     messages = []
        #     if system_message:
        #         messages.append({"role": "system", "content": system_message})
        #     messages.append({"role": "user", "content": prompt})
        #     
        #     response = agent.client.chat.completions.create(
        #         model=agent.llm_config["model"],
        #         messages=messages,
        #         temperature=agent.llm_config["temperature"],
        #         max_tokens=agent.llm_config["max_tokens"]
        #     )
        #     
        #     return {
        #         "content": response.choices[0].message.content,
        #         "tokens_used": response.usage.total_tokens,
        #         "success": True
        #     }
        # except Exception as e:
        #     return {
        #         "error": str(e),
        #         "success": False,
        #         "fallback_response": "DÃ©solÃ©, problÃ¨me technique."
        #     }
        
        # Simulation temporaire
        return {
            "content": f"RÃ©ponse simulÃ©e pour: {prompt[:50]}...",
            "tokens_used": 100,
            "success": True,
            "note": "TODO 3: ImplÃ©mentez l'appel OpenAI rÃ©el"
        }
    
    # Remplacer la mÃ©thode de l'agent
    agent._call_llm = _call_llm
    print("âœ… MÃ©thode _call_llm configurÃ©e (mode simulation)")

# TODO 4: Pattern 1 - Single Agent (10 min)
# ImplÃ©mentez le pattern Single Agent

class SingleAgent(BaseAgent):
    """Pattern 1: Agent simple avec rÃ©ponse LLM directe"""
    
    def __init__(self):
        super().__init__()
        self.pattern_name = "Single Agent"
        print(f"ğŸ¤– Pattern initialisÃ©: {self.pattern_name}")
    
    async def handle_single_request(self, user_input: str) -> Dict[str, Any]:
        """Traiter une requÃªte simple avec le pattern Single Agent"""
        print(f"\nğŸ¯ PATTERN: {self.pattern_name} - '{user_input}'")
        print("=" * 60)
        
        # TODO: ComplÃ©tez l'implÃ©mentation du pattern Single Agent
        
        # Ã‰tape 1: Perception
        perception = self.perceive(user_input)
        
        # Ã‰tape 2: Plan simple
        plan = [{"action": "llm_response", "tool": "direct_llm", "priority": 1, "prompt": user_input}]
        
        # Ã‰tape 3: Action
        system_message = f"""Tu es un assistant IA personnel utile et amical.
        
PrÃ©fÃ©rences: {self.state.user_preferences}
Historique: {len(self.state.conversation_history)} interactions

Instructions:
- RÃ©ponds clairement et de maniÃ¨re concise
- Adapte ton style aux prÃ©fÃ©rences utilisateur
- Sois honnÃªte si tu ne sais pas
- SuggÃ¨re des questions de suivi si pertinent

RequÃªte: {user_input}"""

        result = self._call_llm(user_input, system_message)
        
        # Ã‰tape 4: RÃ©flexion
        reflection = self.reflect([{"step": plan[0], "result": result}])
        
        # Mettre Ã  jour l'Ã©tat
        self.state.total_interactions += 1
        
        response_data = {
            "pattern": self.pattern_name,
            "user_input": user_input,
            "response": result.get("content", result.get("fallback_response", "Erreur")),
            "success": result.get("success", False),
            "tokens_used": result.get("tokens_used", 0),
            "quality_score": reflection["quality_score"],
            "timestamp": datetime.now().isoformat()
        }
        
        print(f"âœ… Single Agent - SuccÃ¨s: {response_data['success']}")
        return response_data
    
    def demo_single_agent(self):
        """DÃ©monstration du pattern Single Agent"""
        print(f"\nğŸ¬ DÃ‰MONSTRATION: {self.pattern_name}")
        print("=" * 60)
        
        demo_queries = [
            "Bonjour ! Comment allez-vous ?",
            "Expliquez-moi ce qu'est un agent IA",
            "Donnez-moi 3 conseils pour bien dormir"
        ]
        
        print(f"ğŸ“‹ Tests: {len(demo_queries)} requÃªtes")
        for i, query in enumerate(demo_queries, 1):
            print(f"\n--- Test {i} ---")
            print(f"ğŸ‘¤ User: {query}")
            
            response = asyncio.run(self.handle_single_request(query))
            print(f"ğŸ¤– Assistant: {response['response']}")
            print(f"ğŸ“Š QualitÃ©: {response['quality_score']:.2f}")

# TODO 5: Pattern 2 - Tool Use Agent (15 min)
# ImplÃ©mentez le systÃ¨me d'outils et le pattern Tool Use

class ToolRegistry:
    """Registre des outils disponibles"""
    
    def __init__(self):
        self.tools = {}
        self._register_default_tools()
    
    def _register_default_tools(self):
        """Enregistrer les outils par dÃ©faut"""
        # TODO: ComplÃ©tez l'enregistrement des outils
        self.register_tool("calculator", self._calculator_tool)
        self.register_tool("web_search", self._web_search_tool)
        self.register_tool("weather", self._weather_tool)
        print("ğŸ”§ Outils par dÃ©faut enregistrÃ©s")
    
    def register_tool(self, name: str, function):
        """Enregistrer un outil"""
        self.tools[name] = {
            "function": function,
            "description": function.__doc__ or f"Outil {name}"
        }
    
    def get_tool(self, name: str):
        """RÃ©cupÃ©rer un outil"""
        return self.tools.get(name, {}).get("function")
    
    def list_tools(self) -> List[str]:
        """Lister les outils"""
        return list(self.tools.keys())
    
    def _calculator_tool(self, expression: str) -> Dict[str, Any]:
        """Calculatrice sÃ©curisÃ©e pour opÃ©rations mathÃ©matiques"""
        # TODO: ImplÃ©mentez la calculatrice
        try:
            # SÃ©curiser l'expression
            allowed_chars = set("0123456789+-*/.() ")
            if not all(c in allowed_chars for c in expression):
                return {"error": "Expression non autorisÃ©e"}
            
            result = eval(expression)
            return {"result": result, "expression": expression, "success": True}
        except Exception as e:
            return {"error": f"Erreur calcul: {e}", "success": False}
    
    def _web_search_tool(self, query: str) -> Dict[str, Any]:
        """Outil de recherche web (simulation)"""
        # TODO: En production, utiliser une vraie API de recherche
        simulated_results = [
            {
                "title": f"RÃ©sultat pour '{query}'",
                "url": f"https://example.com/search?q={query}",
                "snippet": f"Informations pertinentes sur {query}..."
            }
        ]
        return {
            "results": simulated_results,
            "query": query,
            "success": True,
            "note": "RÃ©sultats simulÃ©s"
        }
    
    def _weather_tool(self, location: str) -> Dict[str, Any]:
        """Outil mÃ©tÃ©o (simulation)"""
        # TODO: En production, utiliser OpenWeatherMap
        import random
        return {
            "location": location,
            "temperature": f"{random.randint(10, 25)}Â°C",
            "condition": random.choice(["EnsoleillÃ©", "Nuageux", "Pluvieux"]),
            "success": True,
            "note": "DonnÃ©es simulÃ©es"
        }

class ToolUseAgent(BaseAgent):
    """Pattern 2: Agent avec utilisation d'outils externes"""
    
    def __init__(self):
        super().__init__()
        self.pattern_name = "Tool Use Agent"
        self.tool_registry = ToolRegistry()
        self.available_tools = self.tool_registry.tools
        print(f"ğŸ› ï¸ Pattern initialisÃ©: {self.pattern_name}")
        print(f"ğŸ”§ Outils: {', '.join(self.tool_registry.list_tools())}")
    
    def _detect_tool_need(self, user_input: str) -> List[str]:
        """DÃ©tecter quels outils sont nÃ©cessaires"""
        # TODO: AmÃ©liorez la dÃ©tection d'outils
        needed_tools = []
        user_lower = user_input.lower()
        
        if any(word in user_lower for word in ["calcul", "addition", "multiplication", "combien"]):
            needed_tools.append("calculator")
        if any(word in user_lower for word in ["recherche", "trouve", "information"]):
            needed_tools.append("web_search")
        if any(word in user_lower for word in ["mÃ©tÃ©o", "temps", "tempÃ©rature"]):
            needed_tools.append("weather")
        
        return needed_tools
    
    def _execute_tool(self, tool_name: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """ExÃ©cuter un outil"""
        tool_function = self.tool_registry.get_tool(tool_name)
        
        if not tool_function:
            return {"error": f"Outil '{tool_name}' non trouvÃ©", "success": False}
        
        try:
            # TODO: ComplÃ©tez l'exÃ©cution selon le type d'outil
            if tool_name == "calculator":
                result = tool_function(params.get("expression", ""))
            elif tool_name == "web_search":
                result = tool_function(params.get("query", ""))
            elif tool_name == "weather":
                result = tool_function(params.get("location", "Paris"))
            else:
                result = tool_function(params)
            
            # Enregistrer l'utilisation
            if tool_name not in self.state.tools_used:
                self.state.tools_used.append(tool_name)
            
            result["tool_used"] = tool_name
            return result
        except Exception as e:
            return {"error": f"Erreur {tool_name}: {e}", "success": False}
    
    async def handle_tool_request(self, user_input: str) -> Dict[str, Any]:
        """Traiter une requÃªte avec outils"""
        print(f"\nğŸ¯ PATTERN: {self.pattern_name} - '{user_input}'")
        print("=" * 60)
        
        # TODO: ComplÃ©tez l'implÃ©mentation du pattern Tool Use
        
        # DÃ©tecter les outils nÃ©cessaires
        needed_tools = self._detect_tool_need(user_input)
        print(f"ğŸ”§ Outils dÃ©tectÃ©s: {needed_tools}")
        
        # ExÃ©cuter les outils
        tool_results = []
        for tool in needed_tools:
            params = self._extract_tool_params(user_input, tool)
            result = self._execute_tool(tool, params)
            tool_results.append({"tool": tool, "result": result})
        
        # SynthÃ¨se avec LLM
        synthesis_prompt = self._build_synthesis_prompt(user_input, tool_results)
        llm_result = self._call_llm(synthesis_prompt)
        
        self.state.total_interactions += 1
        
        return {
            "pattern": self.pattern_name,
            "user_input": user_input,
            "tools_used": needed_tools,
            "tool_results": tool_results,
            "synthesis": llm_result.get("content", "Erreur synthÃ¨se"),
            "success": all(r["result"].get("success", True) for r in tool_results),
            "timestamp": datetime.now().isoformat()
        }
    
    def _extract_tool_params(self, user_input: str, tool_name: str) -> Dict[str, Any]:
        """Extraire les paramÃ¨tres pour un outil"""
        # TODO: AmÃ©liorez l'extraction de paramÃ¨tres
        if tool_name == "calculator":
            import re
            numbers = re.findall(r'[\d+\-*/().\s]+', user_input)
            return {"expression": numbers[-1].strip() if numbers else "1+1"}
        elif tool_name == "web_search":
            return {"query": user_input}
        elif tool_name == "weather":
            return {"location": "Paris"}  # TODO: Extraire la vraie ville
        return {}
    
    def _build_synthesis_prompt(self, user_input: str, tool_results: List[Dict]) -> str:
        """Construire le prompt de synthÃ¨se"""
        prompt = f"""SynthÃ©tise les rÃ©sultats d'outils pour rÃ©pondre Ã : {user_input}

RÃ©sultats:
"""
        for tr in tool_results:
            prompt += f"- {tr['tool']}: {tr['result']}\n"
        
        prompt += "\nSynthÃ¨se complÃ¨te:"
        return prompt
    
    def demo_tool_use_agent(self):
        """DÃ©monstration du pattern Tool Use"""
        print(f"\nğŸ¬ DÃ‰MONSTRATION: {self.pattern_name}")
        print("=" * 60)
        
        demo_queries = [
            "Combien font 15 * 8 ?",
            "Quelle est la mÃ©tÃ©o Ã  Paris ?",
            "Recherche des infos sur l'IA"
        ]
        
        for i, query in enumerate(demo_queries, 1):
            print(f"\n--- Test {i} ---")
            print(f"ğŸ‘¤ User: {query}")
            
            response = asyncio.run(self.handle_tool_request(query))
            print(f"ğŸ”§ Outils: {', '.join(response['tools_used'])}")
            print(f"ğŸ¤– SynthÃ¨se: {response['synthesis'][:100]}...")

# TODO 6: Pattern 3 - Human-in-the-Loop (10 min)
# ImplÃ©mentez le pattern Human-in-the-Loop

class HumanInLoopAgent(BaseAgent):
    """Pattern 3: Agent avec validation humaine"""
    
    def __init__(self):
        super().__init__()
        self.pattern_name = "Human-in-the-Loop Agent"
        self.validation_threshold = 0.7
        print(f"ğŸ‘¤ Pattern initialisÃ©: {self.pattern_name}")
    
    def _assess_need_for_validation(self, user_input: str) -> Dict[str, Any]:
        """Ã‰valuer si validation humaine nÃ©cessaire"""
        # TODO: ComplÃ©tez l'Ã©valuation
        indicators = {
            "high_impact": any(word in user_input.lower() for word in ["important", "critique", "urgent"]),
            "financial": any(word in user_input.lower() for word in ["argent", "euro", "coÃ»t"]),
            "decision": any(word in user_input.lower() for word in ["dÃ©cision", "choix"])
        }
        
        score = sum(indicators.values()) / len(indicators)
        
        return {
            "needs_validation": score >= self.validation_threshold,
            "confidence_score": 1 - score,
            "indicators": indicators
        }
    
    def _request_human_validation(self, content: str, reason: str) -> Dict[str, Any]:
        """Simuler validation humaine"""
        print(f"\nğŸš¨ VALIDATION REQUISE")
        print(f"ğŸ“‹ Raison: {reason}")
        print(f"ğŸ“„ Contenu: {content}")
        print(f"â³ En attente validation...")
        
        # TODO: En production, vraie interface utilisateur
        # Simulation automatique
        import random
        approved = random.choice([True, True, False])  # 66% d'approbation
        
        return {
            "approved": approved,
            "feedback": "ApprouvÃ©" if approved else "RefusÃ© - trop risquÃ©",
            "timestamp": datetime.now().isoformat(),
            "success": True
        }
    
    async def handle_human_loop_request(self, user_input: str) -> Dict[str, Any]:
        """Traiter avec validation humaine"""
        print(f"\nğŸ¯ PATTERN: {self.pattern_name} - '{user_input}'")
        print("=" * 60)
        
        # TODO: ComplÃ©tez l'implÃ©mentation Human-in-the-Loop
        
        # Ã‰valuer besoin de validation
        assessment = self._assess_need_for_validation(user_input)
        
        # GÃ©nÃ©rer rÃ©ponse initiale
        initial_response = self._call_llm(user_input)
        final_response = initial_response.get("content", "Erreur")
        
        validation_result = None
        
        # Validation si nÃ©cessaire
        if assessment["needs_validation"]:
            validation_result = self._request_human_validation(
                final_response, 
                "Contenu sensible dÃ©tectÃ©"
            )
            
            if not validation_result["approved"]:
                final_response = f"DÃ©solÃ©, je ne peux traiter cette requÃªte. Raison: {validation_result['feedback']}"
        
        self.state.total_interactions += 1
        
        return {
            "pattern": self.pattern_name,
            "user_input": user_input,
            "validation_required": assessment["needs_validation"],
            "validation_result": validation_result,
            "final_response": final_response,
            "approved": validation_result["approved"] if validation_result else True,
            "confidence": assessment["confidence_score"],
            "timestamp": datetime.now().isoformat()
        }
    
    def demo_human_in_loop_agent(self):
        """DÃ©monstration Human-in-the-Loop"""
        print(f"\nğŸ¬ DÃ‰MONSTRATION: {self.pattern_name}")
        print("=" * 60)
        
        demo_queries = [
            "Bonjour, comment Ã§a va ?",  # Pas de validation
            "C'est une dÃ©cision financiÃ¨re critique",  # Validation requise
            "Quelle est la capitale de France ?"  # Pas de validation
        ]
        
        for i, query in enumerate(demo_queries, 1):
            print(f"\n--- Test {i} ---")
            print(f"ğŸ‘¤ User: {query}")
            
            response = asyncio.run(self.handle_human_loop_request(query))
            print(f"âš–ï¸ Validation: {'Requise' if response['validation_required'] else 'Non requise'}")
            if response['validation_required']:
                print(f"âœ… ApprouvÃ©: {'Oui' if response['approved'] else 'Non'}")
            print(f"ğŸ¤– RÃ©ponse: {response['final_response'][:100]}...")

# TODO 7: Agent Orchestrateur Principal (15 min)
# CrÃ©ez l'agent qui coordonne les 3 patterns

class MyFirstAgent:
    """Agent principal orchestrant les 3 patterns fondamentaux"""
    
    def __init__(self):
        print("\nğŸš€ INITIALISATION AGENT PRINCIPAL")
        print("=" * 60)
        
        # TODO: Initialisez les 3 patterns
        self.single_agent = SingleAgent()
        self.tool_agent = ToolUseAgent()
        self.human_loop_agent = HumanInLoopAgent()
        
        self.global_state = {
            "total_requests": 0,
            "pattern_usage": {"single": 0, "tool": 0, "human_loop": 0},
            "session_start": datetime.now().isoformat()
        }
        
        print("âœ… Tous les patterns initialisÃ©s")
    
    def _select_optimal_pattern(self, user_input: str) -> str:
        """SÃ©lectionner le pattern optimal"""
        user_lower = user_input.lower()
        
        # TODO: AmÃ©liorez la logique de sÃ©lection
        
        # PrioritÃ© 1: Human-in-Loop pour contenus sensibles
        if any(word in user_lower for word in ["important", "critique", "dÃ©cision", "urgent"]):
            return "human_loop"
        
        # PrioritÃ© 2: Tool Use pour outils
        if any(word in user_lower for word in ["calcul", "recherche", "mÃ©tÃ©o", "combien"]):
            return "tool"
        
        # Par dÃ©faut: Single Agent
        return "single"
    
    async def process_request(self, user_input: str) -> Dict[str, Any]:
        """Traiter une requÃªte avec sÃ©lection automatique de pattern"""
        self.global_state["total_requests"] += 1
        
        print(f"\nğŸ¯ ORCHESTRATEUR - RequÃªte #{self.global_state['total_requests']}")
        print(f"ğŸ‘¤ Input: {user_input}")
        
        # SÃ©lection du pattern
        selected_pattern = self._select_optimal_pattern(user_input)
        self.global_state["pattern_usage"][selected_pattern] += 1
        
        print(f"ğŸ§  Pattern sÃ©lectionnÃ©: {selected_pattern.upper()}")
        
        # ExÃ©cution
        try:
            if selected_pattern == "single":
                result = await self.single_agent.handle_single_request(user_input)
            elif selected_pattern == "tool":
                result = await self.tool_agent.handle_tool_request(user_input)
            elif selected_pattern == "human_loop":
                result = await self.human_loop_agent.handle_human_loop_request(user_input)
            
            result["orchestrator"] = {
                "selected_pattern": selected_pattern,
                "request_number": self.global_state["total_requests"]
            }
            
            return result
            
        except Exception as e:
            return {
                "error": f"Erreur: {e}",
                "selected_pattern": selected_pattern,
                "success": False
            }
    
    def get_stats(self) -> Dict[str, Any]:
        """Statistiques globales"""
        total = self.global_state["total_requests"]
        if total > 0:
            percentages = {k: (v/total)*100 for k, v in self.global_state["pattern_usage"].items()}
        else:
            percentages = {"single": 0, "tool": 0, "human_loop": 0}
        
        return {
            "total_requests": total,
            "pattern_distribution": percentages,
            "most_used": max(self.global_state["pattern_usage"], key=self.global_state["pattern_usage"].get) if total > 0 else "Aucun"
        }
    
    async def run_complete_demo(self):
        """DÃ©monstration complÃ¨te des 3 patterns"""
        print(f"\nğŸ¬ DÃ‰MONSTRATION COMPLÃˆTE")
        print("=" * 80)
        
        # ScÃ©narios de test qui correspondent EXACTEMENT aux exemples du README
        demo_scenarios = [
            {"input": "Salut ! Comment Ã§a va ?", "expected": "single"},
            {"input": "Combien font 15 Ã— 8 + 42 ?", "expected": "tool"},
            {"input": "C'est une dÃ©cision financiÃ¨re critique", "expected": "human_loop"},
            {"input": "Quel temps fait-il Ã  Paris ?", "expected": "tool"},
            {"input": "Expliquez-moi l'intelligence artificielle", "expected": "single"}
        ]
        
        results = []
        
        for i, scenario in enumerate(demo_scenarios, 1):
            print(f"\n--- ğŸ¬ DEMO {i}/{len(demo_scenarios)} ---")
            print(f"ğŸ‘¤ User: {scenario['input']}")
            
            result = await self.process_request(scenario["input"])
            results.append(result)
            
            actual = result.get("orchestrator", {}).get("selected_pattern", "unknown")
            match = actual == scenario["expected"]
            
            # Afficher la rÃ©ponse selon le pattern utilisÃ©
            pattern_icons = {"single": "ğŸ’¬", "tool": "ğŸ”§", "human_loop": "ğŸ‘¤"}
            icon = pattern_icons.get(actual, "ğŸ¤–")
            
            if actual == "single":
                response = result.get("response", "Erreur")
                print(f"ğŸ¤– Agent: [{icon} Single Agent] {response[:80]}...")
            elif actual == "tool":
                tools_used = result.get("tools_used", [])
                synthesis = result.get("synthesis", "Erreur")
                print(f"ğŸ¤– Agent: [{icon} Tool Use] Outils: {', '.join(tools_used)}")
                print(f"        â†’ {synthesis[:80]}...")
            elif actual == "human_loop":
                validation = result.get("validation_required", False)
                approved = result.get("approved", False)
                final_response = result.get("final_response", "Erreur")
                print(f"ğŸ¤– Agent: [{icon} Human-in-Loop] Validation: {'Requise' if validation else 'Non'}")
                print(f"        â†’ {'ApprouvÃ©' if approved else 'RefusÃ©'}: {final_response[:60]}...")
            
            print(f"âœ… Pattern correct: {'Oui' if match else 'Non'} (attendu: {scenario['expected']}, utilisÃ©: {actual})")
        
        # Statistiques finales avec confirmation des capacitÃ©s
        stats = self.get_stats()
        pattern_accuracy = sum(1 for r in results if r.get("orchestrator", {}).get("selected_pattern") == demo_scenarios[results.index(r)]["expected"]) / len(results) * 100
        
        print(f"\nğŸ† FÃ‰LICITATIONS ! VOTRE AGENT IA EST PRÃŠT !")
        print("=" * 60)
        print(f"âœ… Assistant personnel intelligent crÃ©Ã© avec succÃ¨s")
        print(f"âœ… 3 patterns fondamentaux maÃ®trisÃ©s")
        print(f"âœ… SÃ©lection automatique de comportement: {pattern_accuracy:.0f}% de prÃ©cision")
        print()
        print(f"ğŸ“Š CAPACITÃ‰S DÃ‰MONTRÃ‰ES:")
        print(f"   ğŸ’¬ Conversation naturelle: {stats['pattern_distribution']['single']:.0f}% des interactions")
        print(f"   ğŸ”§ Utilisation d'outils: {stats['pattern_distribution']['tool']:.0f}% des interactions") 
        print(f"   ğŸ‘¤ Validation humaine: {stats['pattern_distribution']['human_loop']:.0f}% des interactions")
        print()
        print(f"ğŸ“ˆ STATS: {stats['total_requests']} requÃªtes traitÃ©es")
        print(f"ğŸ¯ RÃ‰SULTAT: Un assistant IA qui combine ChatGPT + outils + sÃ©curitÃ© !")
        
        return results

# TODO 8: Test et Validation (5 min)
# Validez les capacitÃ©s de votre agent

def validate_agent_capabilities(agent: MyFirstAgent) -> Dict[str, Any]:
    """Valider les capacitÃ©s selon les critÃ¨res du module"""
    validation = {
        "agentic_loop": False,
        "llm_integration": False,
        "tool_usage": False,
        "memory_system": False,
        "patterns": {"single": False, "tool": False, "human_loop": False},
        "orchestration": False
    }
    
    # TODO: ComplÃ©tez les tests de validation
    
    # Test boucle agentique
    try:
        test_perception = agent.single_agent.perceive("test")
        if "intent" in test_perception and "context" in test_perception:
            validation["agentic_loop"] = True
    except:
        pass
    
    # Test LLM
    if hasattr(agent.single_agent, 'client'):
        validation["llm_integration"] = True
    
    # Test outils
    if len(agent.tool_agent.tool_registry.list_tools()) >= 3:
        validation["tool_usage"] = True
    
    # Test mÃ©moire
    if hasattr(agent.single_agent.state, 'conversation_history'):
        validation["memory_system"] = True
    
    # Test patterns
    validation["patterns"]["single"] = hasattr(agent, "single_agent")
    validation["patterns"]["tool"] = hasattr(agent, "tool_agent") 
    validation["patterns"]["human_loop"] = hasattr(agent, "human_loop_agent")
    
    # Test orchestration
    if hasattr(agent, "_select_optimal_pattern"):
        validation["orchestration"] = True
    
    # Score global
    total_checks = sum([
        validation["agentic_loop"],
        validation["llm_integration"], 
        validation["tool_usage"],
        validation["memory_system"],
        validation["orchestration"]
    ]) + sum(validation["patterns"].values())
    
    validation["overall_score"] = (total_checks / 8) * 100
    
    return validation

def print_validation_report(validation: Dict[str, Any]):
    """Afficher le rapport de validation"""
    print(f"\nğŸ“‹ RAPPORT DE VALIDATION")
    print("=" * 60)
    
    print(f"ğŸ”„ Boucle agentique: {'âœ…' if validation['agentic_loop'] else 'âŒ'}")
    print(f"ğŸ¤– LLM: {'âœ…' if validation['llm_integration'] else 'âŒ'}")
    print(f"ğŸ”§ Outils: {'âœ…' if validation['tool_usage'] else 'âŒ'}")
    print(f"ğŸ’¾ MÃ©moire: {'âœ…' if validation['memory_system'] else 'âŒ'}")
    print(f"ğŸ¯ Orchestration: {'âœ…' if validation['orchestration'] else 'âŒ'}")
    
    print(f"\nğŸ“Š Patterns:")
    for pattern, ok in validation['patterns'].items():
        print(f"   â€¢ {pattern}: {'âœ…' if ok else 'âŒ'}")
    
    score = validation['overall_score']
    grade = "ğŸ† Excellent" if score >= 90 else "ğŸ¥‡ TrÃ¨s bien" if score >= 75 else "ğŸ¥ˆ Bien" if score >= 60 else "ğŸ¥‰ Ã€ amÃ©liorer"
    
    print(f"\nğŸ¯ Score: {score:.1f}% - {grade}")

# FONCTION PRINCIPALE
async def main():
    """Fonction principale pour tester votre agent"""
    print("ğŸ¯ DÃ‰MARRAGE - Premier Agent IA")
    print("ğŸ“ Module 1: Fondamentaux des Agents IA")
    print()
    
    # TODO: DÃ©commentez et complÃ©tez Ã©tape par Ã©tape
    
    print("âš ï¸ TODOs Ã  complÃ©ter:")
    print("1. â¬œ TODO 1: Installation et imports")
    print("2. â¬œ TODO 2: Architecture de base") 
    print("3. â¬œ TODO 3: Configuration LLM")
    print("4. â¬œ TODO 4: Pattern Single Agent")
    print("5. â¬œ TODO 5: Pattern Tool Use")
    print("6. â¬œ TODO 6: Pattern Human-in-Loop") 
    print("7. â¬œ TODO 7: Orchestrateur principal")
    print("8. â¬œ TODO 8: Tests et validation")
    print()
    print("ğŸ“– Consultez STEP_BY_STEP_GUIDE.md pour les instructions dÃ©taillÃ©es")
    print()
    
    # Une fois les TODOs complÃ©tÃ©s, dÃ©commentez ce qui suit:
    
    # # CrÃ©er l'agent principal
    # agent = MyFirstAgent()
    # 
    # # Configuration LLM
    # if setup_llm_integration(agent.single_agent):
    #     implement_llm_call(agent.single_agent)
    #     implement_llm_call(agent.tool_agent)
    #     implement_llm_call(agent.human_loop_agent)
    # 
    # # Lancer la dÃ©monstration
    # demo_results = await agent.run_complete_demo()
    # 
    # # Validation finale
    # validation = validate_agent_capabilities(agent)
    # print_validation_report(validation)
    # 
    # # Sauvegarde
    # results_file = f"first_agent_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    # with open(results_file, "w") as f:
    #     json.dump({
    #         "demo_results": demo_results,
    #         "validation": validation,
    #         "stats": agent.get_stats()
    #     }, f, indent=2, default=str)
    # 
    # print(f"\nğŸ’¾ RÃ©sultats sauvegardÃ©s: {results_file}")
    # return demo_results

if __name__ == "__main__":
    asyncio.run(main())