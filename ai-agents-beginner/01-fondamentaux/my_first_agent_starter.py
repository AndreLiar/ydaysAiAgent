#!/usr/bin/env python3
"""
üéØ Premier Agent IA - Assistant Personnel Intelligent
===================================================

VOTRE MISSION: Cr√©er un assistant IA fonctionnel en 2h qui peut :
üí¨ Converser naturellement (comme ChatGPT)
üîß Utiliser des outils (calculatrice, recherche, m√©t√©o)  
üë§ Demander validation humaine (pour contenus sensibles)
üß† Choisir automatiquement le bon comportement

EXEMPLES DE CE QUE VOTRE AGENT FERA:
üë§ "Salut !" ‚Üí ü§ñ [Chat] "Bonjour ! Comment puis-je vous aider ?"
üë§ "15 √ó 8 + 42 ?" ‚Üí ü§ñ [Outil] üîß "Le r√©sultat est 162"  
üë§ "D√©cision financi√®re" ‚Üí ü§ñ [Validation] üö® "Approbation requise"

INSTRUCTIONS:
- Suivez les 8 TODOs dans l'ordre (1‚Üí2‚Üí3‚Üí...‚Üí8)
- D√©commentez et compl√©tez le code √† chaque √©tape
- Testez apr√®s chaque TODO pour voir les progr√®s
- Consultez STEP_BY_STEP_GUIDE.md pour les explications d√©taill√©es

‚è±Ô∏è Dur√©e: 68 minutes | üîë Pr√©requis: Cl√© OpenAI dans .env
"""

# TODO 1: Installation et Imports (3 min)
# D√©commentez les imports suivants et installez les d√©pendances
# pip install openai python-dotenv requests beautifulsoup4

import os
import json
import asyncio
from datetime import datetime
from dataclasses import dataclass, field
from typing import Dict, Any, List, Optional
from dotenv import load_dotenv

# TODO: D√©commentez les imports OpenAI
# from openai import OpenAI

# Charger les variables d'environnement
load_dotenv()

print("üöÄ Initialisation du Premier Agent IA")
print("üéì Module 1: Fondamentaux des Agents IA")
print("=" * 60)

# TODO 2: Architecture de Base (5 min)
# Compl√©tez les classes de base pour votre agent

@dataclass
class AgentState:
    """√âtat de l'agent entre les interactions"""
    conversation_history: List[Dict[str, Any]] = field(default_factory=list)
    tools_used: List[str] = field(default_factory=list)
    user_preferences: Dict[str, Any] = field(default_factory=dict)
    session_id: str = ""
    total_interactions: int = 0
    
    def __post_init__(self):
        if not self.user_preferences:
            self.user_preferences = {"language": "fr", "style": "friendly"}
        if not self.session_id:
            self.session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

class BaseAgent:
    """Agent IA suivant la boucle Perception ‚Üí Plan ‚Üí Act ‚Üí Reflect"""
    
    def __init__(self):
        # TODO: Initialisez votre client OpenAI
        # api_key = os.getenv("OPENAI_API_KEY")
        # if not api_key:
        #     raise ValueError("‚ùå OPENAI_API_KEY non trouv√©e ! Cr√©ez un fichier .env")
        # self.client = OpenAI(api_key=api_key)
        
        self.client = None  # TODO: Remplacez par l'initialisation OpenAI
        
        self.state = AgentState()
        self.available_tools = {}  # Sera peupl√© dans TODO 5
        
        print(f"ü§ñ Agent initialis√© - Session: {self.state.session_id}")
    
    def perceive(self, user_input: str) -> Dict[str, Any]:
        """√âtape 1: Analyser l'input et le contexte"""
        perception = {
            "user_input": user_input,
            "timestamp": datetime.now().isoformat(),
            "input_length": len(user_input.split()),
            "intent": self._analyze_intent(user_input),
            "context": self._get_relevant_context(),
            "complexity": self._assess_complexity(user_input)
        }
        
        print(f"üîç PERCEPTION: {perception['intent']} (complexit√©: {perception['complexity']})")
        return perception
    
    def plan(self, perception: Dict[str, Any]) -> List[Dict[str, Any]]:
        """√âtape 2: Cr√©er un plan d'action"""
        plan = []
        
        # TODO: Compl√©tez la logique de planification bas√©e sur l'intent
        intent = perception["intent"]
        
        if intent == "calculation":
            plan.append({"action": "use_tool", "tool": "calculator", "priority": 1})
        elif intent == "information":
            plan.append({"action": "search_web", "tool": "web_search", "priority": 1})
        elif intent == "conversation":
            plan.append({"action": "llm_response", "tool": "direct_llm", "priority": 1})
        elif intent == "validation":
            plan.append({"action": "human_input", "tool": "human_loop", "priority": 1})
        
        # Toujours inclure une √©tape de r√©flexion
        plan.append({"action": "reflect", "tool": "self_assessment", "priority": 2})
        
        print(f"üìã PLAN: {len(plan)} √©tapes planifi√©es")
        return plan
    
    def act(self, plan: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """√âtape 3: Ex√©cuter les actions planifi√©es"""
        results = []
        
        for step in sorted(plan, key=lambda x: x["priority"]):
            print(f"‚ö° EX√âCUTION: {step['action']} avec {step['tool']}")
            
            # TODO: Impl√©mentez l'ex√©cution des actions
            if step["action"] == "use_tool":
                result = self._execute_tool(step["tool"], step.get("params", {}))
            elif step["action"] == "llm_response":
                result = self._call_llm(step.get("prompt", ""))
            elif step["action"] == "human_input":
                result = self._request_human_input(step.get("question", ""))
            elif step["action"] == "reflect":
                result = self._self_reflect(results)
            else:
                result = {"error": f"Action inconnue: {step['action']}"}
            
            results.append({
                "step": step,
                "result": result,
                "timestamp": datetime.now().isoformat()
            })
        
        return results
    
    def reflect(self, results: List[Dict[str, Any]], expected_outcome: str = "") -> Dict[str, Any]:
        """√âtape 4: √âvaluer les r√©sultats et s'am√©liorer"""
        reflection = {
            "success": all(r.get("result", {}).get("error") is None for r in results),
            "quality_score": self._assess_quality(results),
            "lessons_learned": [],
            "improvements": [],
            "user_satisfaction": None
        }
        
        # TODO: Compl√©tez la logique de r√©flexion
        for result in results:
            if "error" in result.get("result", {}):
                reflection["lessons_learned"].append(f"Erreur avec {result['step']['tool']}")
                reflection["improvements"].append(f"Am√©liorer {result['step']['action']}")
        
        # M√©moriser pour futures interactions
        self.state.conversation_history.append({
            "perception": results[0].get("perception", {}),
            "plan": [r["step"] for r in results],
            "results": [r["result"] for r in results],
            "reflection": reflection,
            "timestamp": datetime.now().isoformat()
        })
        
        print(f"ü§î R√âFLEXION: Succ√®s={reflection['success']}, Qualit√©={reflection['quality_score']:.2f}")
        return reflection
    
    def _analyze_intent(self, user_input: str) -> str:
        """Analyser l'intention de l'utilisateur"""
        user_lower = user_input.lower()
        
        # TODO: Am√©liorez la d√©tection d'intent
        if any(word in user_lower for word in ["calcul", "addition", "multiplication", "combien"]):
            return "calculation"
        elif any(word in user_lower for word in ["recherche", "trouve", "information", "qu'est-ce"]):
            return "information"
        elif any(word in user_lower for word in ["valide", "v√©rifie", "confirme", "approuve"]):
            return "validation"
        else:
            return "conversation"
    
    def _get_relevant_context(self) -> Dict[str, Any]:
        """R√©cup√©rer le contexte pertinent"""
        recent_history = self.state.conversation_history[-3:] if self.state.conversation_history else []
        return {
            "recent_interactions": len(recent_history),
            "tools_previously_used": list(set(self.state.tools_used[-5:])),
            "user_preferences": self.state.user_preferences
        }
    
    def _assess_complexity(self, user_input: str) -> str:
        """√âvaluer la complexit√© de la demande"""
        complexity_indicators = len([
            word for word in user_input.lower().split() 
            if word in ["et", "puis", "ensuite", "aussi", "√©galement", "apr√®s", "avant"]
        ])
        
        if complexity_indicators >= 2:
            return "high"
        elif complexity_indicators == 1:
            return "medium"
        else:
            return "low"
    
    def _assess_quality(self, results: List[Dict]) -> float:
        """√âvaluer la qualit√© des r√©sultats"""
        if not results:
            return 0.0
        
        successful_results = sum(1 for r in results if not r.get("result", {}).get("error"))
        return successful_results / len(results)
    
    def _execute_tool(self, tool_name: str, params: Dict) -> Dict[str, Any]:
        """Ex√©cuter un outil - sera impl√©ment√© dans TODO 5"""
        return {"error": "Outils pas encore impl√©ment√©s", "tool": tool_name}
    
    def _call_llm(self, prompt: str) -> Dict[str, Any]:
        """Appeler le LLM - sera impl√©ment√© dans TODO 3"""
        return {"error": "LLM pas encore configur√©", "prompt": prompt}
    
    def _request_human_input(self, question: str) -> Dict[str, Any]:
        """Demander une validation humaine - sera impl√©ment√© dans TODO 6"""
        return {"error": "Validation humaine pas encore impl√©ment√©e", "question": question}
    
    def _self_reflect(self, results: List[Dict]) -> Dict[str, Any]:
        """Auto-r√©flexion sur les r√©sultats"""
        return {"reflection": "Auto-r√©flexion basique", "results_count": len(results)}

# TODO 3: Configuration LLM (5 min)
# Compl√©tez l'int√©gration OpenAI

def setup_llm_integration(agent: BaseAgent):
    """Configurer l'int√©gration LLM"""
    print("\nü§ñ √âTAPE: Configuration LLM")
    print("=" * 60)
    
    # TODO: D√©commentez et compl√©tez la configuration OpenAI
    # try:
    #     api_key = os.getenv("OPENAI_API_KEY")
    #     if not api_key:
    #         raise ValueError("‚ùå OPENAI_API_KEY non trouv√©e !")
    #     
    #     agent.client = OpenAI(api_key=api_key)
    #     agent.llm_config = {
    #         "model": "gpt-4",
    #         "temperature": 0.7,
    #         "max_tokens": 500
    #     }
    #     
    #     print("‚úÖ Client OpenAI configur√©")
    #     print(f"üéØ Mod√®le: {agent.llm_config['model']}")
    #     return True
    # except Exception as e:
    #     print(f"‚ùå Erreur configuration LLM: {e}")
    #     return False
    
    print("‚ö†Ô∏è TODO 3: Impl√©mentez la configuration LLM")
    return False

def implement_llm_call(agent: BaseAgent):
    """Impl√©menter l'appel LLM"""
    
    def _call_llm(prompt: str, system_message: str = "") -> Dict[str, Any]:
        """Appeler le LLM avec gestion d'erreurs"""
        # TODO: D√©commentez et compl√©tez l'appel OpenAI
        # try:
        #     messages = []
        #     if system_message:
        #         messages.append({"role": "system", "content": system_message})
        #     messages.append({"role": "user", "content": prompt})
        #     
        #     response = agent.client.chat.completions.create(
        #         model=agent.llm_config["model"],
        #         messages=messages,
        #         temperature=agent.llm_config["temperature"],
        #         max_tokens=agent.llm_config["max_tokens"]
        #     )
        #     
        #     return {
        #         "content": response.choices[0].message.content,
        #         "tokens_used": response.usage.total_tokens,
        #         "success": True
        #     }
        # except Exception as e:
        #     return {
        #         "error": str(e),
        #         "success": False,
        #         "fallback_response": "D√©sol√©, probl√®me technique."
        #     }
        
        # Simulation temporaire
        return {
            "content": f"R√©ponse simul√©e pour: {prompt[:50]}...",
            "tokens_used": 100,
            "success": True,
            "note": "TODO 3: Impl√©mentez l'appel OpenAI r√©el"
        }
    
    # Remplacer la m√©thode de l'agent
    agent._call_llm = _call_llm
    print("‚úÖ M√©thode _call_llm configur√©e (mode simulation)")

# TODO 4: Pattern 1 - Single Agent (10 min)
# Impl√©mentez le pattern Single Agent

class SingleAgent(BaseAgent):
    """Pattern 1: Agent simple avec r√©ponse LLM directe"""
    
    def __init__(self):
        super().__init__()
        self.pattern_name = "Single Agent"
        print(f"ü§ñ Pattern initialis√©: {self.pattern_name}")
    
    async def handle_single_request(self, user_input: str) -> Dict[str, Any]:
        """Traiter une requ√™te simple avec le pattern Single Agent"""
        print(f"\nüéØ PATTERN: {self.pattern_name} - '{user_input}'")
        print("=" * 60)
        
        # TODO: Compl√©tez l'impl√©mentation du pattern Single Agent
        
        # √âtape 1: Perception
        perception = self.perceive(user_input)
        
        # √âtape 2: Plan simple
        plan = [{"action": "llm_response", "tool": "direct_llm", "priority": 1, "prompt": user_input}]
        
        # √âtape 3: Action
        system_message = f"""Tu es un assistant IA personnel utile et amical.
        
Pr√©f√©rences: {self.state.user_preferences}
Historique: {len(self.state.conversation_history)} interactions

Instructions:
- R√©ponds clairement et de mani√®re concise
- Adapte ton style aux pr√©f√©rences utilisateur
- Sois honn√™te si tu ne sais pas
- Sugg√®re des questions de suivi si pertinent

Requ√™te: {user_input}"""

        result = self._call_llm(user_input, system_message)
        
        # √âtape 4: R√©flexion
        reflection = self.reflect([{"step": plan[0], "result": result}])
        
        # Mettre √† jour l'√©tat
        self.state.total_interactions += 1
        
        response_data = {
            "pattern": self.pattern_name,
            "user_input": user_input,
            "response": result.get("content", result.get("fallback_response", "Erreur")),
            "success": result.get("success", False),
            "tokens_used": result.get("tokens_used", 0),
            "quality_score": reflection["quality_score"],
            "timestamp": datetime.now().isoformat()
        }
        
        print(f"‚úÖ Single Agent - Succ√®s: {response_data['success']}")
        return response_data
    
    def demo_single_agent(self):
        """D√©monstration du pattern Single Agent"""
        print(f"\nüé¨ D√âMONSTRATION: {self.pattern_name}")
        print("=" * 60)
        
        demo_queries = [
            "Bonjour ! Comment allez-vous ?",
            "Expliquez-moi ce qu'est un agent IA",
            "Donnez-moi 3 conseils pour bien dormir"
        ]
        
        print(f"üìã Tests: {len(demo_queries)} requ√™tes")
        for i, query in enumerate(demo_queries, 1):
            print(f"\n--- Test {i} ---")
            print(f"üë§ User: {query}")
            
            response = asyncio.run(self.handle_single_request(query))
            print(f"ü§ñ Assistant: {response['response']}")
            print(f"üìä Qualit√©: {response['quality_score']:.2f}")

# TODO 5: Pattern 2 - Tool Use Agent (15 min)
# Impl√©mentez le syst√®me d'outils et le pattern Tool Use

class ToolRegistry:
    """Registre des outils disponibles"""
    
    def __init__(self):
        self.tools = {}
        self._register_default_tools()
    
    def _register_default_tools(self):
        """Enregistrer les outils par d√©faut"""
        # TODO: Compl√©tez l'enregistrement des outils
        self.register_tool("calculator", self._calculator_tool)
        self.register_tool("web_search", self._web_search_tool)
        self.register_tool("weather", self._weather_tool)
        print("üîß Outils par d√©faut enregistr√©s")
    
    def register_tool(self, name: str, function):
        """Enregistrer un outil"""
        self.tools[name] = {
            "function": function,
            "description": function.__doc__ or f"Outil {name}"
        }
    
    def get_tool(self, name: str):
        """R√©cup√©rer un outil"""
        return self.tools.get(name, {}).get("function")
    
    def list_tools(self) -> List[str]:
        """Lister les outils"""
        return list(self.tools.keys())
    
    def _calculator_tool(self, expression: str) -> Dict[str, Any]:
        """Calculatrice s√©curis√©e pour op√©rations math√©matiques"""
        # TODO: Impl√©mentez la calculatrice
        try:
            # S√©curiser l'expression
            allowed_chars = set("0123456789+-*/.() ")
            if not all(c in allowed_chars for c in expression):
                return {"error": "Expression non autoris√©e"}
            
            result = eval(expression)
            return {"result": result, "expression": expression, "success": True}
        except Exception as e:
            return {"error": f"Erreur calcul: {e}", "success": False}
    
    def _web_search_tool(self, query: str) -> Dict[str, Any]:
        """Outil de recherche web (simulation)"""
        # TODO: En production, utiliser une vraie API de recherche
        simulated_results = [
            {
                "title": f"R√©sultat pour '{query}'",
                "url": f"https://example.com/search?q={query}",
                "snippet": f"Informations pertinentes sur {query}..."
            }
        ]
        return {
            "results": simulated_results,
            "query": query,
            "success": True,
            "note": "R√©sultats simul√©s"
        }
    
    def _weather_tool(self, location: str) -> Dict[str, Any]:
        """Outil m√©t√©o (simulation)"""
        # TODO: En production, utiliser OpenWeatherMap
        import random
        return {
            "location": location,
            "temperature": f"{random.randint(10, 25)}¬∞C",
            "condition": random.choice(["Ensoleill√©", "Nuageux", "Pluvieux"]),
            "success": True,
            "note": "Donn√©es simul√©es"
        }

class ToolUseAgent(BaseAgent):
    """Pattern 2: Agent avec utilisation d'outils externes"""
    
    def __init__(self):
        super().__init__()
        self.pattern_name = "Tool Use Agent"
        self.tool_registry = ToolRegistry()
        self.available_tools = self.tool_registry.tools
        print(f"üõ†Ô∏è Pattern initialis√©: {self.pattern_name}")
        print(f"üîß Outils: {', '.join(self.tool_registry.list_tools())}")
    
    def _detect_tool_need(self, user_input: str) -> List[str]:
        """D√©tecter quels outils sont n√©cessaires"""
        # TODO: Am√©liorez la d√©tection d'outils
        needed_tools = []
        user_lower = user_input.lower()
        
        if any(word in user_lower for word in ["calcul", "addition", "multiplication", "combien"]):
            needed_tools.append("calculator")
        if any(word in user_lower for word in ["recherche", "trouve", "information"]):
            needed_tools.append("web_search")
        if any(word in user_lower for word in ["m√©t√©o", "temps", "temp√©rature"]):
            needed_tools.append("weather")
        
        return needed_tools
    
    def _execute_tool(self, tool_name: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """Ex√©cuter un outil"""
        tool_function = self.tool_registry.get_tool(tool_name)
        
        if not tool_function:
            return {"error": f"Outil '{tool_name}' non trouv√©", "success": False}
        
        try:
            # TODO: Compl√©tez l'ex√©cution selon le type d'outil
            if tool_name == "calculator":
                result = tool_function(params.get("expression", ""))
            elif tool_name == "web_search":
                result = tool_function(params.get("query", ""))
            elif tool_name == "weather":
                result = tool_function(params.get("location", "Paris"))
            else:
                result = tool_function(params)
            
            # Enregistrer l'utilisation
            if tool_name not in self.state.tools_used:
                self.state.tools_used.append(tool_name)
            
            result["tool_used"] = tool_name
            return result
        except Exception as e:
            return {"error": f"Erreur {tool_name}: {e}", "success": False}
    
    async def handle_tool_request(self, user_input: str) -> Dict[str, Any]:
        """Traiter une requ√™te avec outils"""
        print(f"\nüéØ PATTERN: {self.pattern_name} - '{user_input}'")
        print("=" * 60)
        
        # TODO: Compl√©tez l'impl√©mentation du pattern Tool Use
        
        # D√©tecter les outils n√©cessaires
        needed_tools = self._detect_tool_need(user_input)
        print(f"üîß Outils d√©tect√©s: {needed_tools}")
        
        # Ex√©cuter les outils
        tool_results = []
        for tool in needed_tools:
            params = self._extract_tool_params(user_input, tool)
            result = self._execute_tool(tool, params)
            tool_results.append({"tool": tool, "result": result})
        
        # Synth√®se avec LLM
        synthesis_prompt = self._build_synthesis_prompt(user_input, tool_results)
        llm_result = self._call_llm(synthesis_prompt)
        
        self.state.total_interactions += 1
        
        return {
            "pattern": self.pattern_name,
            "user_input": user_input,
            "tools_used": needed_tools,
            "tool_results": tool_results,
            "synthesis": llm_result.get("content", "Erreur synth√®se"),
            "success": all(r["result"].get("success", True) for r in tool_results),
            "timestamp": datetime.now().isoformat()
        }
    
    def _extract_tool_params(self, user_input: str, tool_name: str) -> Dict[str, Any]:
        """Extraire les param√®tres pour un outil"""
        # TODO: Am√©liorez l'extraction de param√®tres
        if tool_name == "calculator":
            import re
            numbers = re.findall(r'[\d+\-*/().\s]+', user_input)
            return {"expression": numbers[-1].strip() if numbers else "1+1"}
        elif tool_name == "web_search":
            return {"query": user_input}
        elif tool_name == "weather":
            return {"location": "Paris"}  # TODO: Extraire la vraie ville
        return {}
    
    def _build_synthesis_prompt(self, user_input: str, tool_results: List[Dict]) -> str:
        """Construire le prompt de synth√®se"""
        prompt = f"""Synth√©tise les r√©sultats d'outils pour r√©pondre √†: {user_input}

R√©sultats:
"""
        for tr in tool_results:
            prompt += f"- {tr['tool']}: {tr['result']}\n"
        
        prompt += "\nSynth√®se compl√®te:"
        return prompt
    
    def demo_tool_use_agent(self):
        """D√©monstration du pattern Tool Use"""
        print(f"\nüé¨ D√âMONSTRATION: {self.pattern_name}")
        print("=" * 60)
        
        demo_queries = [
            "Combien font 15 * 8 ?",
            "Quelle est la m√©t√©o √† Paris ?",
            "Recherche des infos sur l'IA"
        ]
        
        for i, query in enumerate(demo_queries, 1):
            print(f"\n--- Test {i} ---")
            print(f"üë§ User: {query}")
            
            response = asyncio.run(self.handle_tool_request(query))
            print(f"üîß Outils: {', '.join(response['tools_used'])}")
            print(f"ü§ñ Synth√®se: {response['synthesis'][:100]}...")

# TODO 6: Pattern 3 - Human-in-the-Loop (10 min)
# Impl√©mentez le pattern Human-in-the-Loop

class HumanInLoopAgent(BaseAgent):
    """Pattern 3: Agent avec validation humaine"""
    
    def __init__(self):
        super().__init__()
        self.pattern_name = "Human-in-the-Loop Agent"
        self.validation_threshold = 0.7
        print(f"üë§ Pattern initialis√©: {self.pattern_name}")
    
    def _assess_need_for_validation(self, user_input: str) -> Dict[str, Any]:
        """√âvaluer si validation humaine n√©cessaire"""
        # TODO: Compl√©tez l'√©valuation
        indicators = {
            "high_impact": any(word in user_input.lower() for word in ["important", "critique", "urgent"]),
            "financial": any(word in user_input.lower() for word in ["argent", "euro", "co√ªt"]),
            "decision": any(word in user_input.lower() for word in ["d√©cision", "choix"])
        }
        
        score = sum(indicators.values()) / len(indicators)
        
        return {
            "needs_validation": score >= self.validation_threshold,
            "confidence_score": 1 - score,
            "indicators": indicators
        }
    
    def _request_human_validation(self, content: str, reason: str) -> Dict[str, Any]:
        """Simuler validation humaine"""
        print(f"\nüö® VALIDATION REQUISE")
        print(f"üìã Raison: {reason}")
        print(f"üìÑ Contenu: {content}")
        print(f"‚è≥ En attente validation...")
        
        # TODO: En production, vraie interface utilisateur
        # Simulation automatique
        import random
        approved = random.choice([True, True, False])  # 66% d'approbation
        
        return {
            "approved": approved,
            "feedback": "Approuv√©" if approved else "Refus√© - trop risqu√©",
            "timestamp": datetime.now().isoformat(),
            "success": True
        }
    
    async def handle_human_loop_request(self, user_input: str) -> Dict[str, Any]:
        """Traiter avec validation humaine"""
        print(f"\nüéØ PATTERN: {self.pattern_name} - '{user_input}'")
        print("=" * 60)
        
        # TODO: Compl√©tez l'impl√©mentation Human-in-the-Loop
        
        # √âvaluer besoin de validation
        assessment = self._assess_need_for_validation(user_input)
        
        # G√©n√©rer r√©ponse initiale
        initial_response = self._call_llm(user_input)
        final_response = initial_response.get("content", "Erreur")
        
        validation_result = None
        
        # Validation si n√©cessaire
        if assessment["needs_validation"]:
            validation_result = self._request_human_validation(
                final_response, 
                "Contenu sensible d√©tect√©"
            )
            
            if not validation_result["approved"]:
                final_response = f"D√©sol√©, je ne peux traiter cette requ√™te. Raison: {validation_result['feedback']}"
        
        self.state.total_interactions += 1
        
        return {
            "pattern": self.pattern_name,
            "user_input": user_input,
            "validation_required": assessment["needs_validation"],
            "validation_result": validation_result,
            "final_response": final_response,
            "approved": validation_result["approved"] if validation_result else True,
            "confidence": assessment["confidence_score"],
            "timestamp": datetime.now().isoformat()
        }
    
    def demo_human_in_loop_agent(self):
        """D√©monstration Human-in-the-Loop"""
        print(f"\nüé¨ D√âMONSTRATION: {self.pattern_name}")
        print("=" * 60)
        
        demo_queries = [
            "Bonjour, comment √ßa va ?",  # Pas de validation
            "C'est une d√©cision financi√®re critique",  # Validation requise
            "Quelle est la capitale de France ?"  # Pas de validation
        ]
        
        for i, query in enumerate(demo_queries, 1):
            print(f"\n--- Test {i} ---")
            print(f"üë§ User: {query}")
            
            response = asyncio.run(self.handle_human_loop_request(query))
            print(f"‚öñÔ∏è Validation: {'Requise' if response['validation_required'] else 'Non requise'}")
            if response['validation_required']:
                print(f"‚úÖ Approuv√©: {'Oui' if response['approved'] else 'Non'}")
            print(f"ü§ñ R√©ponse: {response['final_response'][:100]}...")

# TODO 7: Agent Orchestrateur Principal (15 min)
# Cr√©ez l'agent qui coordonne les 3 patterns

class MyFirstAgent:
    """Agent principal orchestrant les 3 patterns fondamentaux"""
    
    def __init__(self):
        print("\nüöÄ INITIALISATION AGENT PRINCIPAL")
        print("=" * 60)
        
        # TODO: Initialisez les 3 patterns
        self.single_agent = SingleAgent()
        self.tool_agent = ToolUseAgent()
        self.human_loop_agent = HumanInLoopAgent()
        
        self.global_state = {
            "total_requests": 0,
            "pattern_usage": {"single": 0, "tool": 0, "human_loop": 0},
            "session_start": datetime.now().isoformat()
        }
        
        print("‚úÖ Tous les patterns initialis√©s")
    
    def _select_optimal_pattern(self, user_input: str) -> str:
        """S√©lectionner le pattern optimal"""
        user_lower = user_input.lower()
        
        # TODO: Am√©liorez la logique de s√©lection
        
        # Priorit√© 1: Human-in-Loop pour contenus sensibles
        if any(word in user_lower for word in ["important", "critique", "d√©cision", "urgent"]):
            return "human_loop"
        
        # Priorit√© 2: Tool Use pour outils
        if any(word in user_lower for word in ["calcul", "recherche", "m√©t√©o", "combien"]):
            return "tool"
        
        # Par d√©faut: Single Agent
        return "single"
    
    async def process_request(self, user_input: str) -> Dict[str, Any]:
        """Traiter une requ√™te avec s√©lection automatique de pattern"""
        self.global_state["total_requests"] += 1
        
        print(f"\nüéØ ORCHESTRATEUR - Requ√™te #{self.global_state['total_requests']}")
        print(f"üë§ Input: {user_input}")
        
        # S√©lection du pattern
        selected_pattern = self._select_optimal_pattern(user_input)
        self.global_state["pattern_usage"][selected_pattern] += 1
        
        print(f"üß† Pattern s√©lectionn√©: {selected_pattern.upper()}")
        
        # Ex√©cution
        try:
            if selected_pattern == "single":
                result = await self.single_agent.handle_single_request(user_input)
            elif selected_pattern == "tool":
                result = await self.tool_agent.handle_tool_request(user_input)
            elif selected_pattern == "human_loop":
                result = await self.human_loop_agent.handle_human_loop_request(user_input)
            
            result["orchestrator"] = {
                "selected_pattern": selected_pattern,
                "request_number": self.global_state["total_requests"]
            }
            
            return result
            
        except Exception as e:
            return {
                "error": f"Erreur: {e}",
                "selected_pattern": selected_pattern,
                "success": False
            }
    
    def get_stats(self) -> Dict[str, Any]:
        """Statistiques globales"""
        total = self.global_state["total_requests"]
        if total > 0:
            percentages = {k: (v/total)*100 for k, v in self.global_state["pattern_usage"].items()}
        else:
            percentages = {"single": 0, "tool": 0, "human_loop": 0}
        
        return {
            "total_requests": total,
            "pattern_distribution": percentages,
            "most_used": max(self.global_state["pattern_usage"], key=self.global_state["pattern_usage"].get) if total > 0 else "Aucun"
        }
    
    async def run_complete_demo(self):
        """D√©monstration compl√®te des 3 patterns"""
        print(f"\nüé¨ D√âMONSTRATION COMPL√àTE")
        print("=" * 80)
        
        # Sc√©narios de test qui correspondent EXACTEMENT aux exemples du README
        demo_scenarios = [
            {"input": "Salut ! Comment √ßa va ?", "expected": "single"},
            {"input": "Combien font 15 √ó 8 + 42 ?", "expected": "tool"},
            {"input": "C'est une d√©cision financi√®re critique", "expected": "human_loop"},
            {"input": "Quel temps fait-il √† Paris ?", "expected": "tool"},
            {"input": "Expliquez-moi l'intelligence artificielle", "expected": "single"}
        ]
        
        results = []
        
        for i, scenario in enumerate(demo_scenarios, 1):
            print(f"\n--- üé¨ DEMO {i}/{len(demo_scenarios)} ---")
            print(f"üë§ User: {scenario['input']}")
            
            result = await self.process_request(scenario["input"])
            results.append(result)
            
            actual = result.get("orchestrator", {}).get("selected_pattern", "unknown")
            match = actual == scenario["expected"]
            
            # Afficher la r√©ponse selon le pattern utilis√©
            pattern_icons = {"single": "üí¨", "tool": "üîß", "human_loop": "üë§"}
            icon = pattern_icons.get(actual, "ü§ñ")
            
            if actual == "single":
                response = result.get("response", "Erreur")
                print(f"ü§ñ Agent: [{icon} Single Agent] {response[:80]}...")
            elif actual == "tool":
                tools_used = result.get("tools_used", [])
                synthesis = result.get("synthesis", "Erreur")
                print(f"ü§ñ Agent: [{icon} Tool Use] Outils: {', '.join(tools_used)}")
                print(f"        ‚Üí {synthesis[:80]}...")
            elif actual == "human_loop":
                validation = result.get("validation_required", False)
                approved = result.get("approved", False)
                final_response = result.get("final_response", "Erreur")
                print(f"ü§ñ Agent: [{icon} Human-in-Loop] Validation: {'Requise' if validation else 'Non'}")
                print(f"        ‚Üí {'Approuv√©' if approved else 'Refus√©'}: {final_response[:60]}...")
            
            print(f"‚úÖ Pattern correct: {'Oui' if match else 'Non'} (attendu: {scenario['expected']}, utilis√©: {actual})")
        
        # Statistiques finales avec confirmation des capacit√©s
        stats = self.get_stats()
        pattern_accuracy = sum(1 for r in results if r.get("orchestrator", {}).get("selected_pattern") == demo_scenarios[results.index(r)]["expected"]) / len(results) * 100
        
        print(f"\nüèÜ F√âLICITATIONS ! VOTRE AGENT IA EST PR√äT !")
        print("=" * 60)
        print(f"‚úÖ Assistant personnel intelligent cr√©√© avec succ√®s")
        print(f"‚úÖ 3 patterns fondamentaux ma√Ætris√©s")
        print(f"‚úÖ S√©lection automatique de comportement: {pattern_accuracy:.0f}% de pr√©cision")
        print()
        print(f"üìä CAPACIT√âS D√âMONTR√âES:")
        print(f"   üí¨ Conversation naturelle: {stats['pattern_distribution']['single']:.0f}% des interactions")
        print(f"   üîß Utilisation d'outils: {stats['pattern_distribution']['tool']:.0f}% des interactions") 
        print(f"   üë§ Validation humaine: {stats['pattern_distribution']['human_loop']:.0f}% des interactions")
        print()
        print(f"üìà STATS: {stats['total_requests']} requ√™tes trait√©es")
        print(f"üéØ R√âSULTAT: Un assistant IA qui combine ChatGPT + outils + s√©curit√© !")
        
        return results

# TODO 8: Test et Validation (5 min)
# Validez les capacit√©s de votre agent

def validate_agent_capabilities(agent: MyFirstAgent) -> Dict[str, Any]:
    """Valider les capacit√©s selon les crit√®res du module"""
    validation = {
        "agentic_loop": False,
        "llm_integration": False,
        "tool_usage": False,
        "memory_system": False,
        "patterns": {"single": False, "tool": False, "human_loop": False},
        "orchestration": False
    }
    
    # TODO: Compl√©tez les tests de validation
    
    # Test boucle agentique
    try:
        test_perception = agent.single_agent.perceive("test")
        if "intent" in test_perception and "context" in test_perception:
            validation["agentic_loop"] = True
    except:
        pass
    
    # Test LLM
    if hasattr(agent.single_agent, 'client'):
        validation["llm_integration"] = True
    
    # Test outils
    if len(agent.tool_agent.tool_registry.list_tools()) >= 3:
        validation["tool_usage"] = True
    
    # Test m√©moire
    if hasattr(agent.single_agent.state, 'conversation_history'):
        validation["memory_system"] = True
    
    # Test patterns
    validation["patterns"]["single"] = hasattr(agent, "single_agent")
    validation["patterns"]["tool"] = hasattr(agent, "tool_agent") 
    validation["patterns"]["human_loop"] = hasattr(agent, "human_loop_agent")
    
    # Test orchestration
    if hasattr(agent, "_select_optimal_pattern"):
        validation["orchestration"] = True
    
    # Score global
    total_checks = sum([
        validation["agentic_loop"],
        validation["llm_integration"], 
        validation["tool_usage"],
        validation["memory_system"],
        validation["orchestration"]
    ]) + sum(validation["patterns"].values())
    
    validation["overall_score"] = (total_checks / 8) * 100
    
    return validation

def print_validation_report(validation: Dict[str, Any]):
    """Afficher le rapport de validation"""
    print(f"\nüìã RAPPORT DE VALIDATION")
    print("=" * 60)
    
    print(f"üîÑ Boucle agentique: {'‚úÖ' if validation['agentic_loop'] else '‚ùå'}")
    print(f"ü§ñ LLM: {'‚úÖ' if validation['llm_integration'] else '‚ùå'}")
    print(f"üîß Outils: {'‚úÖ' if validation['tool_usage'] else '‚ùå'}")
    print(f"üíæ M√©moire: {'‚úÖ' if validation['memory_system'] else '‚ùå'}")
    print(f"üéØ Orchestration: {'‚úÖ' if validation['orchestration'] else '‚ùå'}")
    
    print(f"\nüìä Patterns:")
    for pattern, ok in validation['patterns'].items():
        print(f"   ‚Ä¢ {pattern}: {'‚úÖ' if ok else '‚ùå'}")
    
    score = validation['overall_score']
    grade = "üèÜ Excellent" if score >= 90 else "ü•á Tr√®s bien" if score >= 75 else "ü•à Bien" if score >= 60 else "ü•â √Ä am√©liorer"
    
    print(f"\nüéØ Score: {score:.1f}% - {grade}")

# FONCTION PRINCIPALE
async def main():
    """Fonction principale pour tester votre agent"""
    print("üéØ D√âMARRAGE - Premier Agent IA")
    print("üéì Module 1: Fondamentaux des Agents IA")
    print()
    
    # TODO: D√©commentez et compl√©tez √©tape par √©tape
    
    print("‚ö†Ô∏è TODOs √† compl√©ter:")
    print("1. ‚¨ú TODO 1: Installation et imports")
    print("2. ‚¨ú TODO 2: Architecture de base") 
    print("3. ‚¨ú TODO 3: Configuration LLM")
    print("4. ‚¨ú TODO 4: Pattern Single Agent")
    print("5. ‚¨ú TODO 5: Pattern Tool Use")
    print("6. ‚¨ú TODO 6: Pattern Human-in-Loop") 
    print("7. ‚¨ú TODO 7: Orchestrateur principal")
    print("8. ‚¨ú TODO 8: Tests et validation")
    print()
    print("üìñ Consultez STEP_BY_STEP_GUIDE.md pour les instructions d√©taill√©es")
    print()
    
    # Une fois les TODOs compl√©t√©s, d√©commentez ce qui suit:
    
    # # Cr√©er l'agent principal
    # agent = MyFirstAgent()
    # 
    # # Configuration LLM
    # if setup_llm_integration(agent.single_agent):
    #     implement_llm_call(agent.single_agent)
    #     implement_llm_call(agent.tool_agent)
    #     implement_llm_call(agent.human_loop_agent)
    # 
    # # Lancer la d√©monstration
    # demo_results = await agent.run_complete_demo()
    # 
    # # Validation finale
    # validation = validate_agent_capabilities(agent)
    # print_validation_report(validation)
    # 
    # # Sauvegarde
    # results_file = f"first_agent_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    # with open(results_file, "w") as f:
    #     json.dump({
    #         "demo_results": demo_results,
    #         "validation": validation,
    #         "stats": agent.get_stats()
    #     }, f, indent=2, default=str)
    # 
    # print(f"\nüíæ R√©sultats sauvegard√©s: {results_file}")
    # return demo_results

if __name__ == "__main__":
    asyncio.run(main())