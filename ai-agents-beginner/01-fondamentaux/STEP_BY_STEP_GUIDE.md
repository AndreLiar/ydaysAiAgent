# ğŸ¯ Guide Ã‰tape par Ã‰tape - Assistant Personnel Intelligent

## ğŸ“š Vue d'Ensemble du Projet

Ce guide vous accompagne dans la construction de votre **assistant IA personnel** qui combine ChatGPT + outils + sÃ©curitÃ©. Vous apprendrez en faisant - chaque Ã©tape vous enseigne des concepts clÃ©s tout en construisant un agent fonctionnel.

### ğŸ¯ Votre Mission
CrÃ©er un assistant IA qui peut :
- **ğŸ’¬ Converser naturellement** comme ChatGPT
- **ğŸ”§ Utiliser des outils** (calculatrice, recherche, mÃ©tÃ©o)
- **ğŸ‘¤ Demander validation** pour contenus sensibles
- **ğŸ§  Choisir automatiquement** le bon comportement

### ğŸ¬ Exemples Concrets de Votre Agent Final
```
ğŸ‘¤ "Salut ! Comment Ã§a va ?"
ğŸ¤– [ğŸ’¬ Single Agent] "Bonjour ! Je vais trÃ¨s bien, merci de demander..."

ğŸ‘¤ "Combien font 15 Ã— 8 + 42 ?"  
ğŸ¤– [ğŸ”§ Tool Use] Calculatrice â†’ "Le rÃ©sultat est 162"

ğŸ‘¤ "C'est une dÃ©cision financiÃ¨re critique"
ğŸ¤– [ğŸ‘¤ Human-in-Loop] ğŸš¨ "Validation requise" â†’ Demande votre accord

ğŸ‘¤ "Quel temps fait-il Ã  Paris ?"
ğŸ¤– [ğŸ”§ Tool Use] MÃ©tÃ©o â†’ "Ã€ Paris : EnsoleillÃ©, 22Â°C"
```

## ğŸš€ DÃ©marrage Rapide

```bash
# 1. Installer les dÃ©pendances
pip install openai python-dotenv requests

# 2. Configurer votre clÃ© API
cp .env.example .env
# Ajouter votre OPENAI_API_KEY dans le fichier .env

# 3. Lancer le projet starter
python my_first_agent_starter.py
```

## ğŸ“‹ Progression Ã‰tape par Ã‰tape

### âœ… TODO 1: Installation et Setup (3 min)

**Concepts appris**: Environnement de dÃ©veloppement et dÃ©pendances

```bash
pip install openai python-dotenv requests beautifulsoup4
```

**Pourquoi ces packages ?**
- `openai`: Client officiel pour GPT-4 et modÃ¨les OpenAI
- `python-dotenv`: Gestion sÃ©curisÃ©e des clÃ©s API
- `requests`: Appels HTTP pour intÃ©grations externes
- `beautifulsoup4`: Parsing HTML pour agents web

### âœ… TODO 2: Architecture de Base (5 min)

**Concepts appris**: Fondements thÃ©oriques et boucle agentique

ImplÃ©mentez la classe `BaseAgent` avec la boucle universelle:

```python
from dataclasses import dataclass
from typing import Dict, Any, List, Optional
from datetime import datetime
import json

@dataclass
class AgentState:
    """Ã‰tat de l'agent entre les interactions"""
    conversation_history: List[Dict[str, Any]]
    tools_used: List[str]
    user_preferences: Dict[str, Any]
    session_id: str
    total_interactions: int = 0
    
    def __post_init__(self):
        if not self.conversation_history:
            self.conversation_history = []
        if not self.tools_used:
            self.tools_used = []
        if not self.user_preferences:
            self.user_preferences = {"language": "fr", "style": "friendly"}

class BaseAgent:
    """Agent IA suivant la boucle Perception â†’ Plan â†’ Act â†’ Reflect"""
    
    def __init__(self):
        self.client = None  # Client OpenAI (TODO 3)
        self.state = AgentState(
            conversation_history=[],
            tools_used=[],
            user_preferences={},
            session_id=f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        )
        self.available_tools = {}  # Registre des outils (TODO 5)
    
    def perceive(self, user_input: str) -> Dict[str, Any]:
        """Ã‰tape 1: Analyser l'input et le contexte"""
        perception = {
            "user_input": user_input,
            "timestamp": datetime.now().isoformat(),
            "input_length": len(user_input.split()),
            "intent": self._analyze_intent(user_input),
            "context": self._get_relevant_context(),
            "complexity": self._assess_complexity(user_input)
        }
        
        print(f"ğŸ” PERCEPTION: {perception['intent']} (complexitÃ©: {perception['complexity']})")
        return perception
    
    def plan(self, perception: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Ã‰tape 2: CrÃ©er un plan d'action"""
        plan = []
        
        # Planification basÃ©e sur l'intent dÃ©tectÃ©
        if perception["intent"] == "calculation":
            plan.append({"action": "use_tool", "tool": "calculator", "priority": 1})
        elif perception["intent"] == "information":
            plan.append({"action": "search_web", "tool": "web_search", "priority": 1})
        elif perception["intent"] == "conversation":
            plan.append({"action": "llm_response", "tool": "direct_llm", "priority": 1})
        elif perception["intent"] == "validation":
            plan.append({"action": "human_input", "tool": "human_loop", "priority": 1})
        
        # Toujours inclure une Ã©tape de rÃ©flexion
        plan.append({"action": "reflect", "tool": "self_assessment", "priority": 2})
        
        print(f"ğŸ“‹ PLAN: {len(plan)} Ã©tapes planifiÃ©es")
        return plan
    
    def act(self, plan: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Ã‰tape 3: ExÃ©cuter les actions planifiÃ©es"""
        results = []
        
        for step in sorted(plan, key=lambda x: x["priority"]):
            print(f"âš¡ EXÃ‰CUTION: {step['action']} avec {step['tool']}")
            
            if step["action"] == "use_tool":
                result = self._execute_tool(step["tool"], step.get("params", {}))
            elif step["action"] == "llm_response":
                result = self._call_llm(step.get("prompt", ""))
            elif step["action"] == "human_input":
                result = self._request_human_input(step.get("question", ""))
            elif step["action"] == "reflect":
                result = self._self_reflect(results)
            else:
                result = {"error": f"Action inconnue: {step['action']}"}
            
            results.append({
                "step": step,
                "result": result,
                "timestamp": datetime.now().isoformat()
            })
        
        return results
    
    def reflect(self, results: List[Dict[str, Any]], expected_outcome: str = "") -> Dict[str, Any]:
        """Ã‰tape 4: Ã‰valuer les rÃ©sultats et s'amÃ©liorer"""
        reflection = {
            "success": all(r.get("result", {}).get("error") is None for r in results),
            "quality_score": self._assess_quality(results),
            "lessons_learned": [],
            "improvements": [],
            "user_satisfaction": None  # Ã€ implÃ©menter avec feedback utilisateur
        }
        
        # Analyser chaque rÃ©sultat
        for result in results:
            if "error" in result.get("result", {}):
                reflection["lessons_learned"].append(f"Erreur avec {result['step']['tool']}")
                reflection["improvements"].append(f"AmÃ©liorer la gestion d'erreur pour {result['step']['action']}")
        
        # MÃ©moriser pour futures interactions
        self.state.conversation_history.append({
            "perception": results[0].get("perception", {}),
            "plan": [r["step"] for r in results],
            "results": [r["result"] for r in results],
            "reflection": reflection,
            "timestamp": datetime.now().isoformat()
        })
        
        print(f"ğŸ¤” RÃ‰FLEXION: SuccÃ¨s={reflection['success']}, QualitÃ©={reflection['quality_score']:.2f}")
        return reflection
    
    def _analyze_intent(self, user_input: str) -> str:
        """Analyser l'intention de l'utilisateur"""
        user_lower = user_input.lower()
        
        if any(word in user_lower for word in ["calcul", "addition", "multiplication", "combien"]):
            return "calculation"
        elif any(word in user_lower for word in ["recherche", "trouve", "information", "qu'est-ce"]):
            return "information"
        elif any(word in user_lower for word in ["valide", "vÃ©rifie", "confirme", "approuve"]):
            return "validation"
        else:
            return "conversation"
    
    def _get_relevant_context(self) -> Dict[str, Any]:
        """RÃ©cupÃ©rer le contexte pertinent"""
        recent_history = self.state.conversation_history[-3:] if self.state.conversation_history else []
        return {
            "recent_interactions": len(recent_history),
            "tools_previously_used": list(set(self.state.tools_used[-5:])),
            "user_preferences": self.state.user_preferences
        }
    
    def _assess_complexity(self, user_input: str) -> str:
        """Ã‰valuer la complexitÃ© de la demande"""
        complexity_indicators = len([
            word for word in user_input.lower().split() 
            if word in ["et", "puis", "ensuite", "aussi", "Ã©galement", "aprÃ¨s", "avant"]
        ])
        
        if complexity_indicators >= 2:
            return "high"
        elif complexity_indicators == 1:
            return "medium"
        else:
            return "low"
```

**Architecture de l'Agent**:
- **Perception**: Analyse de l'input et du contexte
- **Plan**: StratÃ©gie d'action basÃ©e sur l'intent
- **Act**: ExÃ©cution coordonnÃ©e des actions
- **Reflect**: Auto-Ã©valuation et apprentissage

### âœ… TODO 3: Configuration LLM (5 min)

**Concepts appris**: IntÃ©gration OpenAI et gestion des modÃ¨les

ComplÃ©tez l'initialisation du client OpenAI:

```python
import os
from openai import OpenAI

def __init__(self):
    # VÃ©rifier la clÃ© API
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("âŒ OPENAI_API_KEY non trouvÃ©e ! CrÃ©ez un fichier .env")
    
    # Initialiser le client OpenAI
    self.client = OpenAI(api_key=api_key)
    
    # Configuration par dÃ©faut
    self.llm_config = {
        "model": "gpt-4",
        "temperature": 0.7,
        "max_tokens": 500,
        "top_p": 1.0,
        "frequency_penalty": 0.0,
        "presence_penalty": 0.0
    }
    
    # Initialiser l'Ã©tat
    self.state = AgentState(
        conversation_history=[],
        tools_used=[],
        user_preferences={},
        session_id=f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    )
    self.available_tools = {}
    
    print("âœ… Agent initialisÃ© avec GPT-4")
    print(f"ğŸ†” Session: {self.state.session_id}")

def _call_llm(self, prompt: str, system_message: str = "") -> Dict[str, Any]:
    """Appeler le LLM avec gestion d'erreurs"""
    try:
        # Construire les messages
        messages = []
        
        if system_message:
            messages.append({"role": "system", "content": system_message})
        
        # Ajouter le contexte des conversations prÃ©cÃ©dentes
        for interaction in self.state.conversation_history[-2:]:  # 2 derniÃ¨res interactions
            if "user_input" in interaction:
                messages.append({"role": "user", "content": interaction["user_input"]})
            if "response" in interaction:
                messages.append({"role": "assistant", "content": interaction["response"]})
        
        # Ajouter le prompt actuel
        messages.append({"role": "user", "content": prompt})
        
        # Appel API avec retry logic
        response = self.client.chat.completions.create(
            model=self.llm_config["model"],
            messages=messages,
            temperature=self.llm_config["temperature"],
            max_tokens=self.llm_config["max_tokens"],
            top_p=self.llm_config["top_p"],
            frequency_penalty=self.llm_config["frequency_penalty"],
            presence_penalty=self.llm_config["presence_penalty"]
        )
        
        return {
            "content": response.choices[0].message.content,
            "model": response.model,
            "tokens_used": response.usage.total_tokens,
            "cost_estimate": response.usage.total_tokens * 0.00003,  # Estimation GPT-4
            "success": True
        }
        
    except Exception as e:
        return {
            "error": str(e),
            "success": False,
            "fallback_response": "DÃ©solÃ©, je rencontre un problÃ¨me technique. Pouvez-vous reformuler votre demande ?"
        }
```

**Bonnes Pratiques LLM**:
- **Context management**: Historique limitÃ© pour performance
- **Error handling**: Fallback en cas d'Ã©chec API
- **Cost tracking**: Estimation des coÃ»ts en tokens
- **Configuration flexible**: ParamÃ¨tres ajustables

### âœ… TODO 4: Pattern 1 - Single Agent (10 min)

**Concepts appris**: Agent simple avec LLM direct

ImplÃ©mentez le pattern Single Agent:

```python
class SingleAgent(BaseAgent):
    """Pattern 1: Agent simple avec rÃ©ponse LLM directe"""
    
    def __init__(self):
        super().__init__()
        self.pattern_name = "Single Agent"
        print(f"ğŸ¤– Initialisation du pattern: {self.pattern_name}")
    
    async def handle_single_request(self, user_input: str) -> Dict[str, Any]:
        """Traiter une requÃªte simple avec le pattern Single Agent"""
        print(f"\nğŸ¯ PATTERN: {self.pattern_name} - Traitement de: '{user_input}'")
        print("=" * 60)
        
        # Ã‰tape 1: Perception
        perception = self.perceive(user_input)
        
        # Ã‰tape 2: Plan simple pour Single Agent
        plan = [
            {"action": "llm_response", "tool": "direct_llm", "priority": 1, "prompt": user_input}
        ]
        print(f"ğŸ“‹ PLAN: RÃ©ponse LLM directe")
        
        # Ã‰tape 3: Action
        system_message = f"""Tu es un assistant IA personnel utile et amical.
        
PrÃ©fÃ©rences utilisateur: {self.state.user_preferences}
Historique rÃ©cent: {len(self.state.conversation_history)} interactions prÃ©cÃ©dentes

Instructions:
- RÃ©ponds de maniÃ¨re claire et concise
- Adapte ton style aux prÃ©fÃ©rences utilisateur
- Si tu ne sais pas quelque chose, dis-le honnÃªtement
- Sois proactif en suggÃ©rant des actions ou questions de suivi

RequÃªte utilisateur: {user_input}"""

        result = self._call_llm(user_input, system_message)
        
        # Ã‰tape 4: RÃ©flexion
        reflection = self.reflect([{"step": plan[0], "result": result}])
        
        # Mettre Ã  jour l'Ã©tat
        self.state.total_interactions += 1
        
        response_data = {
            "pattern": self.pattern_name,
            "user_input": user_input,
            "response": result.get("content", result.get("fallback_response", "Erreur de traitement")),
            "success": result.get("success", False),
            "tokens_used": result.get("tokens_used", 0),
            "cost_estimate": result.get("cost_estimate", 0),
            "quality_score": reflection["quality_score"],
            "timestamp": datetime.now().isoformat()
        }
        
        print(f"âœ… RÃ©ponse gÃ©nÃ©rÃ©e: {result.get('success', False)}")
        print(f"ğŸ’° CoÃ»t estimÃ©: ${response_data['cost_estimate']:.4f}")
        
        return response_data
    
    def demo_single_agent(self):
        """DÃ©monstration du pattern Single Agent"""
        print(f"\nğŸ¬ DÃ‰MONSTRATION: Pattern {self.pattern_name}")
        print("=" * 60)
        
        demo_queries = [
            "Bonjour ! Comment allez-vous ?",
            "Expliquez-moi ce qu'est un agent IA en termes simples",
            "Quels sont les avantages des voitures Ã©lectriques ?",
            "Pouvez-vous me donner 3 conseils pour mieux dormir ?",
            "RÃ©sumez l'histoire de l'intelligence artificielle en 100 mots"
        ]
        
        print(f"ğŸ“‹ RequÃªtes de test: {len(demo_queries)}")
        for i, query in enumerate(demo_queries, 1):
            print(f"\n--- Test {i}/{len(demo_queries)} ---")
            print(f"ğŸ‘¤ Utilisateur: {query}")
            
            import asyncio
            response = asyncio.run(self.handle_single_request(query))
            
            print(f"ğŸ¤– Assistant: {response['response']}")
            print(f"ğŸ“Š QualitÃ©: {response['quality_score']:.2f}, Tokens: {response['tokens_used']}")
        
        print(f"\nğŸ† DÃ©monstration terminÃ©e!")
        print(f"ğŸ“ˆ Total interactions: {self.state.total_interactions}")
        print(f"ğŸ’¾ Historique: {len(self.state.conversation_history)} conversations")
```

**Cas d'Usage Single Agent**:
- Q&A simple et direct
- RÃ©sumÃ©s de texte
- Explications conceptuelles
- Conseils et recommandations
- Classification de contenu

### âœ… TODO 5: Pattern 2 - Tool Use Agent (15 min)

**Concepts appris**: IntÃ©gration d'outils externes et sÃ©lection dynamique

ImplÃ©mentez le systÃ¨me d'outils et le pattern Tool Use:

```python
import requests
from datetime import datetime
import json
import re

class ToolRegistry:
    """Registre des outils disponibles pour l'agent"""
    
    def __init__(self):
        self.tools = {}
        self._register_default_tools()
    
    def _register_default_tools(self):
        """Enregistrer les outils par dÃ©faut"""
        self.register_tool("calculator", self._calculator_tool)
        self.register_tool("web_search", self._web_search_tool)
        self.register_tool("weather", self._weather_tool)
        self.register_tool("time", self._time_tool)
        self.register_tool("url_checker", self._url_checker_tool)
    
    def register_tool(self, name: str, function):
        """Enregistrer un nouvel outil"""
        self.tools[name] = {
            "function": function,
            "description": function.__doc__ or f"Outil {name}",
            "registered_at": datetime.now().isoformat()
        }
        print(f"ğŸ”§ Outil enregistrÃ©: {name}")
    
    def get_tool(self, name: str):
        """RÃ©cupÃ©rer un outil par son nom"""
        return self.tools.get(name, {}).get("function")
    
    def list_tools(self) -> List[str]:
        """Lister tous les outils disponibles"""
        return list(self.tools.keys())
    
    def _calculator_tool(self, expression: str) -> Dict[str, Any]:
        """Calculatrice sÃ©curisÃ©e pour opÃ©rations mathÃ©matiques"""
        try:
            # SÃ©curiser l'expression (seulement opÃ©rations de base)
            allowed_chars = set("0123456789+-*/.() ")
            if not all(c in allowed_chars for c in expression):
                return {"error": "Expression contient des caractÃ¨res non autorisÃ©s"}
            
            # Ã‰valuer l'expression
            result = eval(expression)
            
            return {
                "result": result,
                "expression": expression,
                "type": "calculation",
                "success": True
            }
            
        except Exception as e:
            return {
                "error": f"Erreur de calcul: {str(e)}",
                "expression": expression,
                "success": False
            }
    
    def _web_search_tool(self, query: str, max_results: int = 3) -> Dict[str, Any]:
        """Outil de recherche web simple (simulation)"""
        try:
            # En production: utiliser une vraie API de recherche (Serper, Bing, etc.)
            # Ici: simulation de rÃ©sultats
            
            simulated_results = [
                {
                    "title": f"RÃ©sultat 1 pour '{query}'",
                    "url": f"https://example.com/result1?q={query.replace(' ', '+')}",
                    "snippet": f"Informations pertinentes sur {query}. Voici un contenu dÃ©taillÃ© qui rÃ©pond Ã  votre recherche..."
                },
                {
                    "title": f"Guide complet: {query}",
                    "url": f"https://guide.com/{query.replace(' ', '-')}",
                    "snippet": f"Guide dÃ©taillÃ© concernant {query} avec des exemples pratiques et des conseils d'experts..."
                },
                {
                    "title": f"FAQ - {query}",
                    "url": f"https://faq.com/questions/{query.replace(' ', '_')}",
                    "snippet": f"Questions frÃ©quemment posÃ©es sur {query} avec des rÃ©ponses complÃ¨tes et Ã  jour..."
                }
            ]
            
            return {
                "results": simulated_results[:max_results],
                "query": query,
                "total_found": len(simulated_results),
                "success": True,
                "note": "RÃ©sultats simulÃ©s - en production, utiliser une vraie API de recherche"
            }
            
        except Exception as e:
            return {
                "error": f"Erreur de recherche: {str(e)}",
                "query": query,
                "success": False
            }
    
    def _weather_tool(self, location: str) -> Dict[str, Any]:
        """Outil mÃ©tÃ©o (simulation)"""
        try:
            # En production: utiliser OpenWeatherMap ou API similaire
            import random
            
            weather_conditions = ["EnsoleillÃ©", "Nuageux", "Pluvieux", "Partiellement nuageux"]
            temperature = random.randint(5, 30)
            condition = random.choice(weather_conditions)
            
            return {
                "location": location,
                "temperature": f"{temperature}Â°C",
                "condition": condition,
                "humidity": f"{random.randint(30, 80)}%",
                "wind": f"{random.randint(5, 25)} km/h",
                "success": True,
                "note": "DonnÃ©es simulÃ©es - en production, utiliser une vraie API mÃ©tÃ©o"
            }
            
        except Exception as e:
            return {
                "error": f"Erreur mÃ©tÃ©o: {str(e)}",
                "location": location,
                "success": False
            }
    
    def _time_tool(self, timezone: str = "Europe/Paris") -> Dict[str, Any]:
        """Outil de gestion du temps"""
        try:
            now = datetime.now()
            
            return {
                "current_time": now.strftime("%H:%M:%S"),
                "current_date": now.strftime("%Y-%m-%d"),
                "day_of_week": now.strftime("%A"),
                "timezone": timezone,
                "timestamp": now.isoformat(),
                "success": True
            }
            
        except Exception as e:
            return {
                "error": f"Erreur temporelle: {str(e)}",
                "success": False
            }
    
    def _url_checker_tool(self, url: str) -> Dict[str, Any]:
        """VÃ©rifier si une URL est accessible"""
        try:
            response = requests.head(url, timeout=5)
            
            return {
                "url": url,
                "status_code": response.status_code,
                "accessible": response.status_code == 200,
                "response_time": "< 5s",
                "success": True
            }
            
        except Exception as e:
            return {
                "url": url,
                "error": f"URL non accessible: {str(e)}",
                "accessible": False,
                "success": False
            }

class ToolUseAgent(BaseAgent):
    """Pattern 2: Agent avec utilisation dynamique d'outils"""
    
    def __init__(self):
        super().__init__()
        self.pattern_name = "Tool Use Agent"
        self.tool_registry = ToolRegistry()
        self.available_tools = self.tool_registry.tools
        print(f"ğŸ› ï¸ Initialisation du pattern: {self.pattern_name}")
        print(f"ğŸ”§ Outils disponibles: {', '.join(self.tool_registry.list_tools())}")
    
    def _detect_tool_need(self, user_input: str) -> List[str]:
        """DÃ©tecter quels outils sont nÃ©cessaires"""
        needed_tools = []
        user_lower = user_input.lower()
        
        # DÃ©tection basÃ©e sur mots-clÃ©s
        if any(word in user_lower for word in ["calcul", "addition", "multiplication", "division", "combien", "rÃ©sultat"]):
            needed_tools.append("calculator")
        
        if any(word in user_lower for word in ["recherche", "trouve", "information", "cherche", "google"]):
            needed_tools.append("web_search")
        
        if any(word in user_lower for word in ["mÃ©tÃ©o", "temps", "pluie", "soleil", "tempÃ©rature"]):
            needed_tools.append("weather")
        
        if any(word in user_lower for word in ["heure", "date", "maintenant", "aujourd'hui", "temps"]):
            needed_tools.append("time")
        
        if any(word in user_lower for word in ["url", "site", "website", "accessible", "lien"]):
            needed_tools.append("url_checker")
        
        return needed_tools
    
    def _execute_tool(self, tool_name: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """ExÃ©cuter un outil avec gestion d'erreurs"""
        tool_function = self.tool_registry.get_tool(tool_name)
        
        if not tool_function:
            return {
                "error": f"Outil '{tool_name}' non trouvÃ©",
                "available_tools": self.tool_registry.list_tools(),
                "success": False
            }
        
        try:
            # Extraire le paramÃ¨tre principal selon l'outil
            if tool_name == "calculator":
                result = tool_function(params.get("expression", ""))
            elif tool_name == "web_search":
                result = tool_function(params.get("query", ""), params.get("max_results", 3))
            elif tool_name == "weather":
                result = tool_function(params.get("location", "Paris"))
            elif tool_name == "time":
                result = tool_function(params.get("timezone", "Europe/Paris"))
            elif tool_name == "url_checker":
                result = tool_function(params.get("url", ""))
            else:
                result = tool_function(params)
            
            # Enregistrer l'utilisation de l'outil
            if tool_name not in self.state.tools_used:
                self.state.tools_used.append(tool_name)
            
            result["tool_used"] = tool_name
            return result
            
        except Exception as e:
            return {
                "error": f"Erreur exÃ©cution {tool_name}: {str(e)}",
                "tool_used": tool_name,
                "success": False
            }
    
    async def handle_tool_request(self, user_input: str) -> Dict[str, Any]:
        """Traiter une requÃªte avec le pattern Tool Use"""
        print(f"\nğŸ¯ PATTERN: {self.pattern_name} - Traitement de: '{user_input}'")
        print("=" * 60)
        
        # Ã‰tape 1: Perception
        perception = self.perceive(user_input)
        
        # Ã‰tape 2: Plan avec dÃ©tection d'outils
        needed_tools = self._detect_tool_need(user_input)
        
        plan = []
        if needed_tools:
            for tool in needed_tools:
                plan.append({
                    "action": "use_tool",
                    "tool": tool,
                    "priority": 1,
                    "params": self._extract_tool_params(user_input, tool)
                })
        
        # Toujours ajouter une synthÃ¨se LLM
        plan.append({
            "action": "llm_synthesis",
            "tool": "direct_llm",
            "priority": 2,
            "context": "tool_results"
        })
        
        print(f"ğŸ“‹ PLAN: {len(needed_tools)} outils + synthÃ¨se LLM")
        print(f"ğŸ”§ Outils sÃ©lectionnÃ©s: {', '.join(needed_tools) if needed_tools else 'Aucun'}")
        
        # Ã‰tape 3: Action
        tool_results = []
        
        # ExÃ©cuter les outils
        for step in [s for s in plan if s["action"] == "use_tool"]:
            print(f"âš¡ ExÃ©cution outil: {step['tool']}")
            result = self._execute_tool(step["tool"], step["params"])
            tool_results.append({"tool": step["tool"], "result": result})
        
        # SynthÃ¨se avec LLM
        synthesis_prompt = self._build_synthesis_prompt(user_input, tool_results)
        llm_result = self._call_llm(synthesis_prompt)
        
        # Ã‰tape 4: RÃ©flexion
        all_results = tool_results + [{"tool": "llm_synthesis", "result": llm_result}]
        reflection = self.reflect([{"step": {"action": "complete_workflow"}, "result": all_results}])
        
        # Mettre Ã  jour l'Ã©tat
        self.state.total_interactions += 1
        
        response_data = {
            "pattern": self.pattern_name,
            "user_input": user_input,
            "tools_used": needed_tools,
            "tool_results": tool_results,
            "synthesis": llm_result.get("content", "Erreur de synthÃ¨se"),
            "success": all(r["result"].get("success", True) for r in tool_results),
            "tokens_used": llm_result.get("tokens_used", 0),
            "quality_score": reflection["quality_score"],
            "timestamp": datetime.now().isoformat()
        }
        
        print(f"âœ… Traitement terminÃ©: {response_data['success']}")
        print(f"ğŸ”§ Outils utilisÃ©s: {len(needed_tools)}")
        
        return response_data
    
    def _extract_tool_params(self, user_input: str, tool_name: str) -> Dict[str, Any]:
        """Extraire les paramÃ¨tres pour un outil spÃ©cifique"""
        params = {}
        
        if tool_name == "calculator":
            # Chercher une expression mathÃ©matique
            math_pattern = r'[\d+\-*/().\s]+'
            matches = re.findall(math_pattern, user_input)
            if matches:
                params["expression"] = matches[-1].strip()
        
        elif tool_name == "web_search":
            # Utiliser tout l'input comme requÃªte
            params["query"] = user_input
            params["max_results"] = 3
        
        elif tool_name == "weather":
            # Chercher un nom de ville
            user_lower = user_input.lower()
            cities = ["paris", "lyon", "marseille", "toulouse", "nice", "nantes", "montpellier", "strasbourg"]
            for city in cities:
                if city in user_lower:
                    params["location"] = city.capitalize()
                    break
            else:
                params["location"] = "Paris"  # Par dÃ©faut
        
        elif tool_name == "time":
            params["timezone"] = "Europe/Paris"  # Par dÃ©faut
        
        elif tool_name == "url_checker":
            # Chercher une URL
            url_pattern = r'https?://[^\s]+'
            matches = re.findall(url_pattern, user_input)
            if matches:
                params["url"] = matches[0]
        
        return params
    
    def _build_synthesis_prompt(self, user_input: str, tool_results: List[Dict]) -> str:
        """Construire le prompt de synthÃ¨se avec rÃ©sultats d'outils"""
        synthesis_prompt = f"""Tu es un assistant IA qui doit synthÃ©tiser les rÃ©sultats d'outils pour rÃ©pondre Ã  l'utilisateur.

RequÃªte utilisateur: {user_input}

RÃ©sultats des outils utilisÃ©s:
"""
        
        for tool_result in tool_results:
            tool_name = tool_result["tool"]
            result = tool_result["result"]
            
            synthesis_prompt += f"\n--- {tool_name.upper()} ---\n"
            
            if result.get("success", False):
                if tool_name == "calculator":
                    synthesis_prompt += f"Calcul: {result.get('expression')} = {result.get('result')}\n"
                elif tool_name == "web_search":
                    synthesis_prompt += f"Recherche: {result.get('query')}\n"
                    for i, res in enumerate(result.get("results", []), 1):
                        synthesis_prompt += f"{i}. {res['title']}: {res['snippet'][:100]}...\n"
                elif tool_name == "weather":
                    synthesis_prompt += f"MÃ©tÃ©o Ã  {result.get('location')}: {result.get('condition')}, {result.get('temperature')}\n"
                elif tool_name == "time":
                    synthesis_prompt += f"Heure actuelle: {result.get('current_time')} le {result.get('current_date')}\n"
                elif tool_name == "url_checker":
                    synthesis_prompt += f"URL {result.get('url')}: {'Accessible' if result.get('accessible') else 'Non accessible'}\n"
            else:
                synthesis_prompt += f"Erreur: {result.get('error', 'Ã‰chec de l\'outil')}\n"
        
        synthesis_prompt += f"""
Instructions pour la synthÃ¨se:
1. Analyse tous les rÃ©sultats d'outils ci-dessus
2. RÃ©ponds de maniÃ¨re complÃ¨te et utile Ã  la requÃªte originale
3. IntÃ¨gre toutes les informations pertinentes
4. Si certains outils ont Ã©chouÃ©, mentionne-le briÃ¨vement
5. Sois concis mais informatif
6. Propose des actions de suivi si pertinentes

SynthÃ¨se:"""
        
        return synthesis_prompt
    
    def demo_tool_use_agent(self):
        """DÃ©monstration du pattern Tool Use Agent"""
        print(f"\nğŸ¬ DÃ‰MONSTRATION: Pattern {self.pattern_name}")
        print("=" * 60)
        
        demo_queries = [
            "Combien font 15 * 8 + 42 ?",
            "Quelle est la mÃ©tÃ©o Ã  Paris aujourd'hui ?",
            "Recherche des informations sur l'intelligence artificielle",
            "Quelle heure est-il maintenant ?",
            "Calcule 100 / 4 et recherche des informations sur les mathÃ©matiques"
        ]
        
        print(f"ğŸ“‹ RequÃªtes de test: {len(demo_queries)}")
        for i, query in enumerate(demo_queries, 1):
            print(f"\n--- Test {i}/{len(demo_queries)} ---")
            print(f"ğŸ‘¤ Utilisateur: {query}")
            
            import asyncio
            response = asyncio.run(self.handle_tool_request(query))
            
            print(f"ğŸ”§ Outils utilisÃ©s: {', '.join(response['tools_used']) if response['tools_used'] else 'Aucun'}")
            print(f"ğŸ¤– SynthÃ¨se: {response['synthesis'][:200]}...")
            print(f"ğŸ“Š SuccÃ¨s: {response['success']}, QualitÃ©: {response['quality_score']:.2f}")
        
        print(f"\nğŸ† DÃ©monstration terminÃ©e!")
        print(f"ğŸ“ˆ Total interactions: {self.state.total_interactions}")
        print(f"ğŸ”§ Outils expÃ©rimentÃ©s: {len(set(self.state.tools_used))}")
```

**Cas d'Usage Tool Use Agent**:
- Calculs mathÃ©matiques complexes
- Recherche d'informations en temps rÃ©el
- VÃ©rification de donnÃ©es externes
- IntÃ©gration avec APIs et services
- Traitement multi-Ã©tapes avec outils

### âœ… TODO 6: Pattern 3 - Human-in-the-Loop (10 min)

**Concepts appris**: Validation humaine et points de contrÃ´le

ImplÃ©mentez le pattern Human-in-the-Loop:

```python
class HumanInLoopAgent(BaseAgent):
    """Pattern 3: Agent avec validation humaine aux points critiques"""
    
    def __init__(self):
        super().__init__()
        self.pattern_name = "Human-in-the-Loop Agent"
        self.validation_threshold = 0.7  # Seuil de confiance pour validation
        self.critical_domains = ["finance", "medical", "legal", "security"]
        print(f"ğŸ‘¤ Initialisation du pattern: {self.pattern_name}")
        print(f"âš–ï¸ Seuil de validation: {self.validation_threshold}")
    
    def _assess_need_for_validation(self, user_input: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Ã‰valuer si une validation humaine est nÃ©cessaire"""
        validation_indicators = {
            "high_impact": any(word in user_input.lower() for word in ["important", "critique", "urgent", "danger"]),
            "critical_domain": any(domain in user_input.lower() for domain in self.critical_domains),
            "uncertainty": any(word in user_input.lower() for word in ["peut-Ãªtre", "probablement", "incertain"]),
            "financial": any(word in user_input.lower() for word in ["argent", "euro", "coÃ»t", "prix", "budget"]),
            "decision_making": any(word in user_input.lower() for word in ["dÃ©cide", "choix", "option", "alternative"])
        }
        
        score = sum(validation_indicators.values()) / len(validation_indicators)
        
        return {
            "needs_validation": score >= self.validation_threshold,
            "confidence_score": 1 - score,
            "indicators": validation_indicators,
            "reason": self._get_validation_reason(validation_indicators)
        }
    
    def _get_validation_reason(self, indicators: Dict[str, bool]) -> str:
        """Obtenir la raison de la validation"""
        reasons = []
        if indicators["high_impact"]:
            reasons.append("Impact potentiellement Ã©levÃ©")
        if indicators["critical_domain"]:
            reasons.append("Domaine critique dÃ©tectÃ©")
        if indicators["financial"]:
            reasons.append("Implications financiÃ¨res")
        if indicators["decision_making"]:
            reasons.append("Prise de dÃ©cision requise")
        
        return "; ".join(reasons) if reasons else "Validation prÃ©ventive"
    
    def _request_human_validation(self, content: str, reason: str, options: List[str] = None) -> Dict[str, Any]:
        """Simuler une demande de validation humaine"""
        print(f"\nğŸš¨ VALIDATION HUMAINE REQUISE")
        print(f"ğŸ“‹ Raison: {reason}")
        print(f"ğŸ“„ Contenu Ã  valider:")
        print(f"   {content}")
        
        if options:
            print(f"ğŸ”˜ Options disponibles:")
            for i, option in enumerate(options, 1):
                print(f"   {i}. {option}")
        
        # Simulation de l'interaction humaine
        print(f"\nâ³ En attente de validation humaine...")
        
        # En production: vraie interface utilisateur
        # Ici: simulation automatique pour dÃ©mo
        
        import random
        simulated_responses = [
            {"approved": True, "feedback": "ValidÃ© - procÃ©dez"},
            {"approved": True, "feedback": "ApprouvÃ© avec modifications mineures"},
            {"approved": False, "feedback": "RefusÃ© - trop risquÃ©"},
            {"approved": False, "feedback": "ReportÃ© - plus d'informations nÃ©cessaires"}
        ]
        
        response = random.choice(simulated_responses)
        
        print(f"âœ… RÃ©ponse humaine reÃ§ue: {'ApprouvÃ©' if response['approved'] else 'RefusÃ©'}")
        print(f"ğŸ’¬ Feedback: {response['feedback']}")
        
        return {
            "approved": response["approved"],
            "feedback": response["feedback"],
            "timestamp": datetime.now().isoformat(),
            "validation_time": "3.2s",  # SimulÃ©
            "validator": "human_operator",
            "success": True
        }
    
    async def handle_human_loop_request(self, user_input: str) -> Dict[str, Any]:
        """Traiter une requÃªte avec le pattern Human-in-the-Loop"""
        print(f"\nğŸ¯ PATTERN: {self.pattern_name} - Traitement de: '{user_input}'")
        print("=" * 60)
        
        # Ã‰tape 1: Perception
        perception = self.perceive(user_input)
        
        # Ã‰tape 2: Ã‰valuation du besoin de validation
        validation_assessment = self._assess_need_for_validation(user_input, perception)
        
        print(f"âš–ï¸ Ã‰valuation validation: {'Requise' if validation_assessment['needs_validation'] else 'Non requise'}")
        print(f"ğŸ¯ Score de confiance: {validation_assessment['confidence_score']:.2f}")
        
        # Ã‰tape 3: Plan avec points de validation
        plan = []
        
        # GÃ©nÃ©rer une rÃ©ponse initiale
        plan.append({
            "action": "llm_response",
            "tool": "direct_llm",
            "priority": 1,
            "prompt": user_input
        })
        
        # Ajouter validation si nÃ©cessaire
        if validation_assessment["needs_validation"]:
            plan.append({
                "action": "human_validation",
                "tool": "human_loop",
                "priority": 2,
                "reason": validation_assessment["reason"]
            })
            
            plan.append({
                "action": "post_validation_action",
                "tool": "conditional_llm",
                "priority": 3
            })
        
        print(f"ğŸ“‹ PLAN: {len(plan)} Ã©tapes {'avec validation' if validation_assessment['needs_validation'] else 'sans validation'}")
        
        # Ã‰tape 4: ExÃ©cution
        
        # 1. GÃ©nÃ©rer rÃ©ponse initiale
        initial_response = self._call_llm(user_input, self._build_careful_system_message())
        
        workflow_results = [{
            "step": "initial_response",
            "result": initial_response
        }]
        
        final_response = initial_response.get("content", "Erreur de gÃ©nÃ©ration")
        validation_result = None
        
        # 2. Validation humaine si requise
        if validation_assessment["needs_validation"]:
            validation_result = self._request_human_validation(
                content=final_response,
                reason=validation_assessment["reason"],
                options=["Approuver", "Modifier", "Refuser", "Reporter"]
            )
            
            workflow_results.append({
                "step": "human_validation",
                "result": validation_result
            })
            
            # 3. Action post-validation
            if validation_result["approved"]:
                print("âœ… Validation approuvÃ©e - rÃ©ponse autorisÃ©e")
                if "modification" in validation_result["feedback"].lower():
                    # RÃ©gÃ©nÃ©rer avec feedback
                    modification_prompt = f"""Modifie cette rÃ©ponse selon le feedback humain:

RÃ©ponse originale: {final_response}

Feedback humain: {validation_result['feedback']}

RÃ©ponse modifiÃ©e:"""
                    
                    modified_response = self._call_llm(modification_prompt)
                    final_response = modified_response.get("content", final_response)
                    
                    workflow_results.append({
                        "step": "post_validation_modification",
                        "result": modified_response
                    })
            else:
                print("âŒ Validation refusÃ©e - rÃ©ponse bloquÃ©e")
                final_response = f"DÃ©solÃ©, je ne peux pas traiter cette requÃªte. Raison: {validation_result['feedback']}"
        
        # Ã‰tape 5: RÃ©flexion
        reflection = self.reflect(workflow_results)
        
        # Mettre Ã  jour l'Ã©tat
        self.state.total_interactions += 1
        
        response_data = {
            "pattern": self.pattern_name,
            "user_input": user_input,
            "validation_required": validation_assessment["needs_validation"],
            "validation_reason": validation_assessment.get("reason"),
            "validation_result": validation_result,
            "final_response": final_response,
            "confidence_score": validation_assessment["confidence_score"],
            "approved": validation_result["approved"] if validation_result else True,
            "workflow_steps": len(workflow_results),
            "quality_score": reflection["quality_score"],
            "timestamp": datetime.now().isoformat()
        }
        
        print(f"âœ… Traitement terminÃ©: {'ApprouvÃ©' if response_data['approved'] else 'RefusÃ©'}")
        print(f"ğŸ”„ Ã‰tapes workflow: {response_data['workflow_steps']}")
        
        return response_data
    
    def _build_careful_system_message(self) -> str:
        """Construire un message systÃ¨me pour rÃ©ponses prudentes"""
        return """Tu es un assistant IA responsable qui doit Ãªtre particuliÃ¨rement prudent.

Instructions spÃ©ciales:
- Sois conscient que tes rÃ©ponses peuvent avoir un impact important
- Indique clairement tes limites et incertitudes
- Pour les sujets critiques (finance, mÃ©dical, lÃ©gal), recommande de consulter un expert
- Utilise des formulations prudentes: "Il semble que", "D'aprÃ¨s mes informations", "Je recommande de vÃ©rifier"
- Si tu n'es pas sÃ»r, dis-le ouvertement
- Propose toujours de chercher des informations supplÃ©mentaires

Ton rÃ´le est d'Ãªtre utile tout en restant responsable et transparent sur tes limites."""
    
    def demo_human_in_loop_agent(self):
        """DÃ©monstration du pattern Human-in-the-Loop"""
        print(f"\nğŸ¬ DÃ‰MONSTRATION: Pattern {self.pattern_name}")
        print("=" * 60)
        
        demo_queries = [
            "Bonjour, comment Ã§a va ?",  # Pas de validation
            "Peux-tu m'aider Ã  choisir un investissement financier important ?",  # Validation requise
            "Quel est le traitement mÃ©dical pour une migraine ?",  # Validation requise
            "Quelle est la capitale de la France ?",  # Pas de validation
            "Je dois prendre une dÃ©cision critique pour mon entreprise",  # Validation requise
        ]
        
        print(f"ğŸ“‹ RequÃªtes de test: {len(demo_queries)}")
        for i, query in enumerate(demo_queries, 1):
            print(f"\n--- Test {i}/{len(demo_queries)} ---")
            print(f"ğŸ‘¤ Utilisateur: {query}")
            
            import asyncio
            response = asyncio.run(self.handle_human_loop_request(query))
            
            print(f"âš–ï¸ Validation requise: {'Oui' if response['validation_required'] else 'Non'}")
            if response['validation_required']:
                print(f"ğŸ“‹ Raison: {response['validation_reason']}")
                print(f"âœ… ApprouvÃ©: {'Oui' if response['approved'] else 'Non'}")
            print(f"ğŸ¤– RÃ©ponse finale: {response['final_response'][:150]}...")
            print(f"ğŸ“Š Confiance: {response['confidence_score']:.2f}, Ã‰tapes: {response['workflow_steps']}")
        
        print(f"\nğŸ† DÃ©monstration terminÃ©e!")
        print(f"ğŸ“ˆ Total interactions: {self.state.total_interactions}")
        print(f"ğŸ‘¤ Validations humaines simulÃ©es")
```

**Cas d'Usage Human-in-the-Loop**:
- DÃ©cisions Ã  fort impact
- Domaines rÃ©glementÃ©s (finance, mÃ©dical, lÃ©gal)
- Validation de contenu sensible
- ContrÃ´le qualitÃ© pour production
- Apprentissage supervisÃ©

### âœ… TODO 7: Agent Orchestrateur Principal (15 min)

**Concepts appris**: Coordination des patterns et sÃ©lection intelligente

CrÃ©ez l'agent principal qui orchestre les 3 patterns:

```python
class MyFirstAgent:
    """Agent principal orchestrant les 3 patterns fondamentaux"""
    
    def __init__(self):
        print("ğŸš€ Initialisation de votre Premier Agent IA")
        print("=" * 60)
        
        # Initialiser les 3 patterns
        self.single_agent = SingleAgent()
        self.tool_agent = ToolUseAgent()
        self.human_loop_agent = HumanInLoopAgent()
        
        # Ã‰tat global
        self.global_state = {
            "total_requests": 0,
            "pattern_usage": {"single": 0, "tool": 0, "human_loop": 0},
            "success_rate": 0.0,
            "session_start": datetime.now().isoformat()
        }
        
        print("âœ… Tous les patterns initialisÃ©s")
        print("ğŸ¯ Agent prÃªt pour l'interaction")
    
    def _select_optimal_pattern(self, user_input: str) -> str:
        """SÃ©lectionner le pattern optimal pour la requÃªte"""
        user_lower = user_input.lower()
        
        # PrioritÃ© 1: Human-in-the-Loop pour contenus sensibles
        sensitive_keywords = ["important", "critique", "dÃ©cision", "finance", "medical", "urgent"]
        if any(keyword in user_lower for keyword in sensitive_keywords):
            return "human_loop"
        
        # PrioritÃ© 2: Tool Use pour requÃªtes nÃ©cessitant des outils
        tool_keywords = ["calcul", "recherche", "mÃ©tÃ©o", "heure", "information", "combien", "trouve"]
        if any(keyword in user_lower for keyword in tool_keywords):
            return "tool"
        
        # Par dÃ©faut: Single Agent pour conversation simple
        return "single"
    
    async def process_request(self, user_input: str) -> Dict[str, Any]:
        """Traiter une requÃªte en sÃ©lectionnant le pattern optimal"""
        self.global_state["total_requests"] += 1
        
        print(f"\nğŸ¯ ORCHESTRATEUR - RequÃªte #{self.global_state['total_requests']}")
        print(f"ğŸ‘¤ Input: {user_input}")
        print("=" * 60)
        
        # SÃ©lection du pattern
        selected_pattern = self._select_optimal_pattern(user_input)
        self.global_state["pattern_usage"][selected_pattern] += 1
        
        print(f"ğŸ§  Pattern sÃ©lectionnÃ©: {selected_pattern.upper()}")
        
        # ExÃ©cution selon le pattern
        try:
            if selected_pattern == "single":
                result = await self.single_agent.handle_single_request(user_input)
            elif selected_pattern == "tool":
                result = await self.tool_agent.handle_tool_request(user_input)
            elif selected_pattern == "human_loop":
                result = await self.human_loop_agent.handle_human_loop_request(user_input)
            else:
                raise ValueError(f"Pattern inconnu: {selected_pattern}")
            
            # Enrichir avec mÃ©tadonnÃ©es orchestrateur
            result["orchestrator"] = {
                "selected_pattern": selected_pattern,
                "request_number": self.global_state["total_requests"],
                "global_state": self.global_state.copy()
            }
            
            return result
            
        except Exception as e:
            error_result = {
                "error": f"Erreur orchestrateur: {str(e)}",
                "selected_pattern": selected_pattern,
                "user_input": user_input,
                "success": False,
                "timestamp": datetime.now().isoformat()
            }
            return error_result
    
    def get_stats(self) -> Dict[str, Any]:
        """Obtenir les statistiques globales"""
        total_requests = self.global_state["total_requests"]
        
        if total_requests > 0:
            pattern_percentages = {
                pattern: (count / total_requests) * 100 
                for pattern, count in self.global_state["pattern_usage"].items()
            }
        else:
            pattern_percentages = {"single": 0, "tool": 0, "human_loop": 0}
        
        return {
            "session_duration": f"Depuis {self.global_state['session_start']}",
            "total_requests": total_requests,
            "pattern_distribution": pattern_percentages,
            "most_used_pattern": max(self.global_state["pattern_usage"], key=self.global_state["pattern_usage"].get) if total_requests > 0 else "Aucun",
            "tools_available": len(self.tool_agent.tool_registry.list_tools()),
            "agents_active": 3
        }
    
    async def run_complete_demo(self):
        """DÃ©monstration complÃ¨te des 3 patterns"""
        print(f"\nğŸ¬ DÃ‰MONSTRATION COMPLÃˆTE - 3 Patterns Fondamentaux")
        print("=" * 80)
        
        # ScÃ©narios diversifiÃ©s pour tester tous les patterns
        demo_scenarios = [
            # Single Agent
            {"input": "Bonjour ! Peux-tu te prÃ©senter ?", "expected_pattern": "single"},
            {"input": "Explique-moi ce qu'est un agent IA", "expected_pattern": "single"},
            
            # Tool Use
            {"input": "Combien font 15 * 8 + 42 ?", "expected_pattern": "tool"},
            {"input": "Recherche des informations sur Python", "expected_pattern": "tool"},
            {"input": "Quelle est la mÃ©tÃ©o Ã  Paris ?", "expected_pattern": "tool"},
            
            # Human-in-the-Loop
            {"input": "Aide-moi Ã  prendre une dÃ©cision financiÃ¨re importante", "expected_pattern": "human_loop"},
            {"input": "C'est un sujet mÃ©dical critique", "expected_pattern": "human_loop"},
        ]
        
        print(f"ğŸ“‹ ScÃ©narios de test: {len(demo_scenarios)}")
        
        results = []
        
        for i, scenario in enumerate(demo_scenarios, 1):
            print(f"\n--- ScÃ©nario {i}/{len(demo_scenarios)} ---")
            print(f"ğŸ‘¤ Input: {scenario['input']}")
            print(f"ğŸ¯ Pattern attendu: {scenario['expected_pattern']}")
            
            result = await self.process_request(scenario["input"])
            
            actual_pattern = result.get("orchestrator", {}).get("selected_pattern", "unknown")
            pattern_match = actual_pattern == scenario["expected_pattern"]
            
            print(f"ğŸ¤– Pattern utilisÃ©: {actual_pattern}")
            print(f"âœ… Correspondance: {'Oui' if pattern_match else 'Non'}")
            
            # Afficher la rÃ©ponse selon le pattern
            if actual_pattern == "single":
                print(f"ğŸ’¬ RÃ©ponse: {result.get('response', 'N/A')[:100]}...")
            elif actual_pattern == "tool":
                tools_used = result.get('tools_used', [])
                print(f"ğŸ”§ Outils: {', '.join(tools_used) if tools_used else 'Aucun'}")
                print(f"ğŸ’¬ SynthÃ¨se: {result.get('synthesis', 'N/A')[:100]}...")
            elif actual_pattern == "human_loop":
                validation = result.get('validation_required', False)
                approved = result.get('approved', False)
                print(f"ğŸ‘¤ Validation: {'Requise' if validation else 'Non requise'}")
                print(f"âœ… ApprouvÃ©: {'Oui' if approved else 'Non'}")
                print(f"ğŸ’¬ RÃ©ponse: {result.get('final_response', 'N/A')[:100]}...")
            
            results.append({
                "scenario": scenario,
                "result": result,
                "pattern_match": pattern_match
            })
        
        # Statistiques finales
        print(f"\nğŸ“Š STATISTIQUES FINALES")
        print("=" * 60)
        
        stats = self.get_stats()
        print(f"ğŸ“ˆ Total requÃªtes: {stats['total_requests']}")
        print(f"ğŸ¯ Pattern le plus utilisÃ©: {stats['most_used_pattern']}")
        print(f"ğŸ“Š Distribution des patterns:")
        for pattern, percentage in stats['pattern_distribution'].items():
            print(f"   â€¢ {pattern}: {percentage:.1f}%")
        
        pattern_accuracy = sum(1 for r in results if r["pattern_match"]) / len(results) * 100
        print(f"ğŸ¯ PrÃ©cision sÃ©lection pattern: {pattern_accuracy:.1f}%")
        
        success_rate = sum(1 for r in results if r["result"].get("success", True)) / len(results) * 100
        print(f"âœ… Taux de succÃ¨s global: {success_rate:.1f}%")
        
        return {
            "demo_results": results,
            "final_stats": stats,
            "pattern_accuracy": pattern_accuracy,
            "success_rate": success_rate
        }

# Point d'entrÃ©e principal
async def main():
    """Fonction principale pour tester l'agent"""
    print("ğŸ¯ DÃ©marrage de votre Premier Agent IA")
    print("ğŸ“ Module 1: Fondamentaux des Agents IA")
    print()
    
    # CrÃ©er l'agent principal
    agent = MyFirstAgent()
    
    # Lancer la dÃ©monstration complÃ¨te
    demo_results = await agent.run_complete_demo()
    
    # Sauvegarde des rÃ©sultats
    results_file = f"agent_demo_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(results_file, "w", encoding="utf-8") as f:
        json.dump(demo_results, f, indent=2, ensure_ascii=False, default=str)
    
    print(f"\nğŸ’¾ RÃ©sultats sauvegardÃ©s: {results_file}")
    
    return demo_results

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
```

### âœ… TODO 8: Test et Validation (5 min)

**Concepts appris**: Validation et mÃ©triques de performance

Ajoutez le systÃ¨me de tests:

```python
def validate_agent_capabilities(agent: MyFirstAgent) -> Dict[str, Any]:
    """Valider les capacitÃ©s de l'agent selon les critÃ¨res du module"""
    validation_results = {
        "agentic_loop": False,
        "llm_integration": False,
        "tool_usage": False,
        "memory_system": False,
        "pattern_implementation": {"single": False, "tool": False, "human_loop": False},
        "orchestration": False,
        "error_handling": False,
        "overall_score": 0.0
    }
    
    # Test de la boucle agentique
    try:
        test_input = "Test de validation"
        perception = agent.single_agent.perceive(test_input)
        plan = agent.single_agent.plan(perception)
        
        if all(key in perception for key in ["user_input", "intent", "context"]):
            validation_results["agentic_loop"] = True
        if len(plan) > 0 and all("action" in step for step in plan):
            validation_results["agentic_loop"] = True
    except:
        pass
    
    # Test d'intÃ©gration LLM
    try:
        if agent.single_agent.client is not None:
            validation_results["llm_integration"] = True
    except:
        pass
    
    # Test des outils
    try:
        tools = agent.tool_agent.tool_registry.list_tools()
        if len(tools) >= 3:  # Minimum 3 outils
            validation_results["tool_usage"] = True
    except:
        pass
    
    # Test de la mÃ©moire
    try:
        if hasattr(agent.single_agent.state, "conversation_history"):
            validation_results["memory_system"] = True
    except:
        pass
    
    # Test des patterns
    validation_results["pattern_implementation"]["single"] = hasattr(agent, "single_agent")
    validation_results["pattern_implementation"]["tool"] = hasattr(agent, "tool_agent")
    validation_results["pattern_implementation"]["human_loop"] = hasattr(agent, "human_loop_agent")
    
    # Test d'orchestration
    try:
        if hasattr(agent, "_select_optimal_pattern") and hasattr(agent, "global_state"):
            validation_results["orchestration"] = True
    except:
        pass
    
    # Test de gestion d'erreurs
    try:
        # Tester avec input invalide
        import asyncio
        result = asyncio.run(agent.process_request(""))
        if "error" in result or result.get("success") is not None:
            validation_results["error_handling"] = True
    except:
        validation_results["error_handling"] = True  # Exception capturÃ©e = bonne gestion
    
    # Calculer le score global
    total_checks = 0
    passed_checks = 0
    
    for key, value in validation_results.items():
        if key == "pattern_implementation":
            for pattern_key, pattern_value in value.items():
                total_checks += 1
                if pattern_value:
                    passed_checks += 1
        elif key != "overall_score":
            total_checks += 1
            if value:
                passed_checks += 1
    
    validation_results["overall_score"] = (passed_checks / total_checks) * 100
    
    return validation_results

# Ajouter Ã  la fin du main()
def print_validation_report(validation_results: Dict[str, Any]):
    """Afficher le rapport de validation"""
    print(f"\nğŸ“‹ RAPPORT DE VALIDATION")
    print("=" * 60)
    
    print(f"ğŸ”„ Boucle agentique: {'âœ…' if validation_results['agentic_loop'] else 'âŒ'}")
    print(f"ğŸ¤– IntÃ©gration LLM: {'âœ…' if validation_results['llm_integration'] else 'âŒ'}")
    print(f"ğŸ”§ SystÃ¨me d'outils: {'âœ…' if validation_results['tool_usage'] else 'âŒ'}")
    print(f"ğŸ’¾ SystÃ¨me mÃ©moire: {'âœ…' if validation_results['memory_system'] else 'âŒ'}")
    print(f"ğŸ¯ Orchestration: {'âœ…' if validation_results['orchestration'] else 'âŒ'}")
    print(f"âš ï¸ Gestion d'erreurs: {'âœ…' if validation_results['error_handling'] else 'âŒ'}")
    
    print(f"\nğŸ“Š Patterns implÃ©mentÃ©s:")
    for pattern, implemented in validation_results['pattern_implementation'].items():
        print(f"   â€¢ {pattern}: {'âœ…' if implemented else 'âŒ'}")
    
    score = validation_results['overall_score']
    if score >= 90:
        grade = "ğŸ† Excellent"
    elif score >= 75:
        grade = "ğŸ¥‡ TrÃ¨s bien"
    elif score >= 60:
        grade = "ğŸ¥ˆ Bien"
    else:
        grade = "ğŸ¥‰ Ã€ amÃ©liorer"
    
    print(f"\nğŸ¯ Score global: {score:.1f}% - {grade}")
    
    if score < 100:
        print(f"\nğŸ’¡ Points d'amÃ©lioration:")
        if not validation_results['agentic_loop']:
            print("   â€¢ ImplÃ©menter la boucle Perception â†’ Plan â†’ Act â†’ Reflect")
        if not validation_results['llm_integration']:
            print("   â€¢ Configurer correctement l'intÃ©gration OpenAI")
        if not validation_results['tool_usage']:
            print("   â€¢ Ajouter au moins 3 outils fonctionnels")
        if not validation_results['memory_system']:
            print("   â€¢ ImplÃ©menter la persistance des conversations")
```

## ğŸ¯ RÃ©sultat Final

AprÃ¨s avoir complÃ©tÃ© tous les TODOs, vous aurez crÃ©Ã© :

### ğŸ“ Fichiers GÃ©nÃ©rÃ©s
- âœ… `my_first_agent_starter.py` - Votre agent complet avec 3 patterns
- âœ… `agent_demo_results_*.json` - RÃ©sultats des tests automatiques
- âœ… Historique des conversations en mÃ©moire

### ğŸ“ CompÃ©tences Acquises
- **Boucle Agentique**: Perception â†’ Plan â†’ Act â†’ Reflect
- **Patterns de Base**: Single Agent, Tool Use, Human-in-Loop
- **Orchestration**: SÃ©lection intelligente de patterns
- **IntÃ©gration**: LLM + Tools + Memory = Agent

### ğŸš€ Applications Possibles
- Assistant personnel intelligent
- Agent de support client basique
- SystÃ¨me de validation avec contrÃ´le humain
- Prototype d'agent mÃ©tier simple

## ğŸ¬ DÃ©monstration

Lancez votre agent terminÃ© :

```bash
python my_first_agent_starter.py
```

Le systÃ¨me exÃ©cutera automatiquement :
1. âœ… Test des 3 patterns fondamentaux
2. âœ… DÃ©monstration de l'orchestration intelligente
3. âœ… Validation automatique des capacitÃ©s
4. âœ… GÃ©nÃ©ration de rapport de performance
5. âœ… Sauvegarde des rÃ©sultats

## ğŸ”§ Personnalisation

### Adapter Ã  Votre Domaine
1. **Outils**: Ajoutez des outils spÃ©cifiques Ã  votre mÃ©tier
2. **Patterns**: Personnalisez les seuils de validation
3. **LLM**: Configurez les prompts selon votre contexte
4. **MÃ©moire**: Adaptez les prÃ©fÃ©rences utilisateur

### Extensions Possibles
1. **Persistance**: Base de donnÃ©es pour mÃ©moire long-terme
2. **Interface**: Web UI ou chat pour interaction
3. **Monitoring**: MÃ©triques avancÃ©es et logs
4. **SÃ©curitÃ©**: Authentification et autorisation

## ğŸ† Validation des Acquis

Vous maÃ®trisez le module si vous pouvez :
- [ ] Expliquer la boucle agentique et ses 4 Ã©tapes
- [ ] ImplÃ©menter les 3 patterns de base de zÃ©ro
- [ ] Orchestrer plusieurs patterns selon le contexte
- [ ] IntÃ©grer LLM, outils et mÃ©moire dans un agent cohÃ©rent
- [ ] Identifier quand utiliser chaque pattern

## ğŸ”— Ressources pour Aller Plus Loin

- [OpenAI API Documentation](https://platform.openai.com/docs)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [LangChain Documentation](https://docs.langchain.com/) (prÃ©paration Module 2)

---

ğŸ¯ **FÃ©licitations !** Vous avez maÃ®trisÃ© les fondamentaux et Ãªtes prÃªt pour les patterns avancÃ©s !