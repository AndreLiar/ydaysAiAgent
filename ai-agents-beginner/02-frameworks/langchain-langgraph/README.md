# ğŸ¦œ LangChain/LangGraph - Apprentissage par Projet

## ğŸ“š Vue d'ensemble

LangChain est le framework le plus populaire pour dÃ©velopper des applications avec des modÃ¨les de langage. LangGraph ajoute des capacitÃ©s de workflows stateful et de routage conditionnel.

### ğŸ¯ Cas d'usage principaux
- **RAG complexe** : SystÃ¨mes de question-rÃ©ponse avec documents
- **Workflows multi-Ã©tapes** : Orchestration de tÃ¢ches complexes  
- **IntÃ©gration APIs** : Connexion avec 100+ services externes
- **Monitoring production** : ObservabilitÃ© et mÃ©triques avancÃ©es

## ğŸ“‚ Structure du Projet

```
langchain-langgraph/
â”œâ”€â”€ my_rag_system_starter.py     # ğŸ¯ Template principal avec TODOs guidÃ©s
â”œâ”€â”€ STEP_BY_STEP_GUIDE.md        # ğŸ“– Guide d'apprentissage progressif
â””â”€â”€ documents/                   # ğŸ“„ Documents d'exemple (auto-gÃ©nÃ©rÃ©s)
```

### ğŸ“ Approche PÃ©dagogique
Ce module utilise l'**apprentissage par projet** : vous apprenez LangChain/LangGraph en construisant un systÃ¨me RAG complet avec 13 Ã©tapes guidÃ©es.

## ğŸš€ Installation

```bash
# DÃ©pendances principales
pip install langchain langchain-openai langchain-community

# Pour RAG et vectorisation
pip install chromadb pypdf

# Pour LangGraph
pip install langgraph

# Pour monitoring
pip install langsmith
```

## âš™ï¸ Configuration

CrÃ©ez un fichier `.env` :

```bash
OPENAI_API_KEY=your_openai_api_key_here
LANGCHAIN_API_KEY=your_langsmith_key_here  # Optionnel pour monitoring
```

## ğŸš€ DÃ©marrage du Projet

### ğŸ“– Guide Complet d'Apprentissage

1. **Lisez le guide Ã©tape par Ã©tape** : [`STEP_BY_STEP_GUIDE.md`](./STEP_BY_STEP_GUIDE.md)
2. **Ouvrez le template** : [`my_rag_system_starter.py`](./my_rag_system_starter.py)
3. **Suivez les 13 TODOs** dans l'ordre pour apprendre

### ğŸ¯ Progression d'Apprentissage

```bash
# 1. Installer et configurer
pip install langchain langchain-openai langchain-community chromadb langgraph pypdf
cp .env.example .env  # Ajouter votre OPENAI_API_KEY

# 2. Lancer le template
python my_rag_system_starter.py

# 3. Suivre les TODOs dans l'ordre :
#    TODO 1-2: Setup et imports
#    TODO 3-4: Architecture et mÃ©triques  
#    TODO 5-6: Initialisation
#    TODO 7-8: Pipeline RAG
#    TODO 9-10: Workflow LangGraph
#    TODO 11-13: Query et monitoring
```

### ğŸ“š Ce que Vous Apprendrez

| TODO | Concept | DurÃ©e |
|------|---------|-------|
| 1-2 | **Ã‰cosystÃ¨me LangChain** - Imports et architecture | 5 min |
| 3-4 | **Ã‰tats et mÃ©triques** - Workflows stateful | 10 min |
| 5-6 | **Configuration** - Services IA et documents | 12 min |
| 7-8 | **Pipeline RAG** - Ingestion et chaÃ®nes | 25 min |
| 9-10 | **LangGraph** - Workflows et monitoring | 20 min |
| 11-13 | **Production** - Query et mÃ©triques | 15 min |

## ğŸ¬ Votre SystÃ¨me RAG en Action

### ğŸ¤– **Ce que Votre SystÃ¨me LangChain Fera ConcrÃ¨tement**

**DÃ©monstration avec documents techniques** :

```
ğŸ“„ DOCUMENTS INGÃ‰RÃ‰S:
- "Guide_IA_2024.pdf" (45 pages)
- "Best_Practices_ML.txt" (12 pages)  
- "Architecture_Agents.md" (8 pages)

ğŸ‘¤ USER: "Comment optimiser les performances d'un agent IA ?"

ğŸ” SYSTÃˆME RAG LANGCHAIN:

ğŸ“Š Analyse complexitÃ©: "Question technique avancÃ©e â†’ Workflow complexe"

ğŸ” Recherche vectorielle:
   âœ… TrouvÃ© 4 passages pertinents dans Guide_IA_2024.pdf (pages 23-25)
   âœ… TrouvÃ© 2 passages dans Best_Practices_ML.txt (section Performance)
   
ğŸ§  LangGraph Workflow:
   1. Route â†’ Analyse complexe
   2. Enrichissement â†’ Sources multiples 
   3. SynthÃ¨se â†’ RÃ©ponse structurÃ©e
   4. Validation â†’ Score qualitÃ©: 94%

ğŸ¯ RÃ‰PONSE GÃ‰NÃ‰RÃ‰E:
"Pour optimiser les performances d'un agent IA, voici les approches clÃ©s:

## ğŸš€ Optimisations Techniques
1. **Prompts optimisÃ©s**: RÃ©duire de 40% les tokens (Guide_IA_2024.pdf, p.23)
2. **Caching intelligent**: Mise en cache des requÃªtes frÃ©quentes
3. **ModÃ¨les adaptÃ©s**: Choisir le bon modÃ¨le par tÃ¢che

## ğŸ“Š MÃ©triques de Performance  
- Latence cible: <3s par requÃªte
- Accuracy: >90% sur votre domaine
- CoÃ»t: Optimisation token/rÃ©ponse

**Sources citÃ©es:**
- Guide_IA_2024.pdf, pages 23-25 âœ…
- Best_Practices_ML.txt, section Performance âœ…"

ğŸ“Š MÃ‰TRIQUES AUTOMATIQUES:
â±ï¸ Temps rÃ©ponse: 4.2s | ğŸ’° CoÃ»t: $0.003 | ğŸ¯ Score qualitÃ©: 94%
ğŸ“ˆ Monitoring: conversation_metrics.json mis Ã  jour
```

### ğŸ† **RÃ©sultat Final Concret**

Ã€ la fin, vous aurez un **systÃ¨me RAG production-ready** qui :
- **Ingestion automatique** : PDF/TXT â†’ vectorisation â†’ base de connaissances
- **Q&A intelligent** : Questions â†’ recherche sÃ©mantique â†’ rÃ©ponses avec sources
- **Routage adaptatif** : Simple/complexe â†’ workflow LangGraph optimisÃ©
- **Monitoring temps rÃ©el** : Latence, coÃ»ts, qualitÃ© â†’ mÃ©triques JSON
- **Production ready** : Gestion erreurs, retry logic, observabilitÃ©

## ğŸ“ Validation des CompÃ©tences

### âœ… **CritÃ¨res de RÃ©ussite**

Votre projet est rÃ©ussi quand vous avez complÃ©tÃ© **tous les TODOs** et votre systÃ¨me :

#### ğŸ“Š **Performance** :
- RÃ©pond en < 5s par requÃªte
- IngÃ¨re des documents sans erreur
- Affiche des mÃ©triques temps rÃ©el

#### ğŸ¯ **FonctionnalitÃ©s** :
- Pipeline RAG complet (ingestion â†’ vectorisation â†’ Q&A)
- Workflow LangGraph avec routage intelligent 
- Monitoring avec mÃ©triques de coÃ»ts et performance
- Documentation gÃ©nÃ©rÃ©e automatiquement

#### ğŸ¬ **DÃ©monstration** :
Votre systÃ¨me doit rÃ©ussir la dÃ©monstration automatique avec les 5 questions test du `run_demo()`.

### ğŸ“ **Fichiers GÃ©nÃ©rÃ©s**

AprÃ¨s complÃ©tion des TODOs, vous aurez crÃ©Ã© :
```
langchain-langgraph/
â”œâ”€â”€ my_rag_system_starter.py     # âœ… Votre implÃ©mentation complÃ¨te
â”œâ”€â”€ documents/                   # âœ… Documents d'exemple
â”œâ”€â”€ chroma_db/                   # âœ… Base vectorielle persistante  
â”œâ”€â”€ metrics.json                 # âœ… MÃ©triques de performance
â””â”€â”€ STEP_BY_STEP_GUIDE.md        # ğŸ“– Guide de rÃ©fÃ©rence
```

### ğŸ† **Validation Finale**

Pour valider vos acquis, vous devez pouvoir :
- [ ] Expliquer le pipeline RAG end-to-end
- [ ] Modifier les prompts pour votre domaine
- [ ] Ajouter de nouveaux types de documents
- [ ] Comprendre les mÃ©triques de performance
- [ ] Adapter le routage LangGraph pour vos besoins

## ğŸš€ Personnalisation et Extensions

### ğŸ¯ **Adapter Ã  Votre Domaine**

Une fois les TODOs complÃ©tÃ©s, personnalisez votre systÃ¨me :

#### ğŸ“„ **Vos Documents** :
```bash
# Remplacez les documents d'exemple
rm -rf documents/*
# Ajoutez vos PDF/TXT dans documents/
cp ~/mes-docs/* documents/
```

#### ğŸ¨ **Prompts SpÃ©cialisÃ©s** :
```python
# Dans TODO 8, modifiez le template
template = """Tu es un expert en [VOTRE DOMAINE].
Utilise le contexte pour rÃ©pondre avec l'expertise de [VOTRE SECTEUR].

Contexte: {context}
Question: {question}

RÃ©ponse d'expert :"""
```

#### ğŸ”„ **Routage PersonnalisÃ©** :
```python
# Dans TODO 9, adaptez la logique de complexitÃ©
def analyze_query(state):
    question = state["question"]
    # Votre logique mÃ©tier spÃ©cifique
    if "technique" in question.lower():
        state["routing_decision"] = "complex"
    return state
```

### âš¡ **Optimisations AvancÃ©es**

#### ğŸ“ˆ **Performance** :
- Caching des embeddings frÃ©quents
- Chunking optimisÃ© pour votre type de documents
- Recherche hybride (semantic + keyword)

#### ğŸ’° **CoÃ»ts** :
- ModÃ¨les locaux avec Ollama
- Embeddings moins chers (text-embedding-3-small)
- Rate limiting intelligent

#### ğŸ” **QualitÃ©** :
- Ã‰valuation automatique des rÃ©ponses
- Feedback utilisateur intÃ©grÃ©
- Re-ranking des rÃ©sultats

## ğŸ”§ Patterns avancÃ©s

### Pattern Agent avec outils
```python
from langchain.agents import create_openai_functions_agent
from langchain.tools import Tool

# DÃ©finir des outils
tools = [
    Tool(name="Calculator", func=calculator, description="Calculs mathÃ©matiques"),
    Tool(name="Search", func=search, description="Recherche web")
]

# CrÃ©er l'agent
agent = create_openai_functions_agent(llm, tools, prompt)
```

### Pattern RAG avec filtres
```python
# Filtrage par mÃ©tadonnÃ©es
retriever = vectorstore.as_retriever(
    search_kwargs={
        "k": 4,
        "filter": {"source": "documentation"}
    }
)
```

### Pattern Streaming
```python
# RÃ©ponses en streaming
for chunk in chain.stream({"input": "Question"}):
    print(chunk, end="", flush=True)
```

## ğŸ“ˆ MÃ©triques de performance

### Temps de rÃ©ponse cibles :
- **ChaÃ®nes simples** : < 2s
- **RAG queries** : < 5s  
- **Workflows complexes** : < 10s

### QualitÃ© RAG :
- **Relevance score** : > 0.7
- **Context utilization** : > 80%
- **Answer accuracy** : > 90%

## ğŸš¨ Troubleshooting

### Erreurs courantes :

**âŒ "API Key not found"**
```bash
# VÃ©rifiez votre .env
echo $OPENAI_API_KEY
```

**âŒ "Chroma database locked"**
```bash
# Supprimez le dossier de la DB
rm -rf ./chroma_db
```

**âŒ "Rate limit exceeded"**
```python
# Ajoutez des dÃ©lais
import time
time.sleep(1)  # Entre les appels
```

**âŒ "Memory usage high"**
```python
# Limitez la taille des chunks
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,  # Plus petit
    chunk_overlap=50
)
```

## ğŸ”— Ressources complÃ©mentaires

### Documentation officielle :
- [LangChain Docs](https://docs.langchain.com/)
- [LangGraph Guide](https://langchain-ai.github.io/langgraph/)
- [LangSmith Platform](https://smith.langchain.com/)

### Tutoriels vidÃ©o :
- [LangChain Crash Course](https://www.youtube.com/watch?v=lG7Uxts9SXs)
- [RAG from Scratch](https://www.youtube.com/watch?v=wd7TZ4w1mSw)

### CommunautÃ© :
- [Discord LangChain](https://discord.gg/langchain) (50K+ membres)
- [GitHub Discussions](https://github.com/langchain-ai/langchain/discussions)

## ğŸ’¡ Conseils pour la production

### ğŸ”’ SÃ©curitÃ© :
- Ne jamais exposer les clÃ©s API
- Valider toutes les entrÃ©es utilisateur
- ImplÃ©menter des rate limits

### âš¡ Performance :
- Utiliser le caching pour les embeddings
- Optimiser la taille des chunks RAG
- ImplÃ©menter le streaming pour l'UX

### ğŸ“Š Monitoring :
- Tracker toutes les mÃ©triques importantes
- Alertes sur les Ã©checs/lenteurs
- Logs dÃ©taillÃ©s pour le debugging

### ğŸ§ª Testing :
- Tests unitaires pour chaque composant
- Tests d'intÃ©gration end-to-end
- Tests de charge pour la scalabilitÃ©

---

ğŸ¯ **Objectif final** : MaÃ®triser LangChain pour crÃ©er des applications IA robustes et scalables en production !