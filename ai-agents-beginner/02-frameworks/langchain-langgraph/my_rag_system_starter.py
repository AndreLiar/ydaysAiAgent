#!/usr/bin/env python3
"""
ğŸ¯ PROJET RAG SYSTEM - STARTER TEMPLATE
Apprenez LangChain et LangGraph en construisant un systÃ¨me RAG complet !

ğŸ“š Ce fichier est votre template de dÃ©marrage. Suivez les TODO pour apprendre.
ğŸš€ Ã€ la fin, vous aurez un systÃ¨me RAG production-ready avec monitoring.

Temps estimÃ©: 45 minutes
DifficultÃ©: â­â­â­â­ (AvancÃ©)
"""

import os
from typing import Dict, List, Any, Optional, TypedDict, Annotated
from datetime import datetime
from dataclasses import dataclass
from pathlib import Path

# TODO 1: Installer les dÃ©pendances
# pip install langchain langchain-openai langchain-community chromadb langgraph pypdf

# TODO 2: Importer les modules nÃ©cessaires
# ğŸ’¡ APPRENTISSAGE: Comprendre l'Ã©cosystÃ¨me LangChain
from dotenv import load_dotenv
# Ajouter vos imports ici:
# from langchain_openai import ChatOpenAI, OpenAIEmbeddings
# from langchain_community.vectorstores import Chroma
# from langchain_community.document_loaders import PyPDFLoader, TextLoader
# from langchain.text_splitter import RecursiveCharacterTextSplitter
# from langchain.chains import RetrievalQA
# from langchain.prompts import PromptTemplate
# from langgraph.graph import StateGraph, END
# from langgraph.checkpoint.memory import MemorySaver

load_dotenv()

# TODO 3: DÃ©finir l'Ã©tat du workflow LangGraph
# ğŸ’¡ APPRENTISSAGE: Les workflows stateful avec LangGraph
class RAGWorkflowState(TypedDict):
    """Ã‰tat partagÃ© du workflow RAG"""
    # DÃ©finir les variables d'Ã©tat ici
    pass

# TODO 4: CrÃ©er une classe pour collecter les mÃ©triques
# ğŸ’¡ APPRENTISSAGE: Monitoring et observabilitÃ© en production
@dataclass
class RAGMetrics:
    """MÃ©triques de performance du systÃ¨me RAG"""
    # Ajouter les champs de mÃ©triques ici
    pass

class MyRAGSystem:
    """
    ğŸ¯ VOTRE SYSTÃˆME RAG COMPLET
    
    Objectifs d'apprentissage:
    1. ğŸ”— MaÃ®triser les chaÃ®nes LangChain
    2. ğŸ“„ ImplÃ©menter un pipeline RAG robuste
    3. ğŸ”„ CrÃ©er des workflows LangGraph avec Ã©tats
    4. ğŸ“Š IntÃ©grer monitoring et mÃ©triques
    5. ğŸ›¡ï¸ GÃ©rer les erreurs et la production
    """
    
    def __init__(self):
        """
        TODO 5: Initialiser votre systÃ¨me RAG
        ğŸ’¡ APPRENTISSAGE: Configuration des services LangChain
        
        Ã€ faire:
        - Configurer ChatOpenAI avec votre clÃ© API
        - Configurer OpenAIEmbeddings
        - Initialiser les variables d'instance
        - PrÃ©parer le systÃ¨me de mÃ©triques
        """
        print("ğŸš€ Initialisation de votre systÃ¨me RAG...")
        
        # VÃ©rifier la clÃ© API
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("âŒ OPENAI_API_KEY non trouvÃ©e ! CrÃ©ez un fichier .env")
        
        # TODO: Initialiser vos services IA ici
        # self.llm = ...
        # self.embeddings = ...
        # self.vectorstore = None
        # self.workflow = None
        # self.metrics = []
        
        print("âœ… Configuration de base terminÃ©e")
    
    def create_documents_folder(self):
        """
        TODO 6: PrÃ©parer les documents d'exemple
        ğŸ’¡ APPRENTISSAGE: Gestion des donnÃ©es pour RAG
        """
        docs_dir = Path("./documents")
        docs_dir.mkdir(exist_ok=True)
        
        # CrÃ©er des documents d'exemple si le dossier est vide
        if not any(docs_dir.iterdir()):
            sample_docs = {
                "ai_guide.txt": """
# Guide Intelligence Artificielle

L'Intelligence Artificielle (IA) rÃ©volutionne notre monde. Ce guide couvre:

## 1. Fondamentaux de l'IA
- Machine Learning: apprentissage automatique Ã  partir de donnÃ©es
- Deep Learning: rÃ©seaux de neurones profonds
- NLP: traitement du langage naturel

## 2. Applications Pratiques
- Chatbots et assistants virtuels
- Reconnaissance d'images
- Traduction automatique
- VÃ©hicules autonomes

## 3. Frameworks Populaires
- LangChain: orchestration d'agents IA
- AutoGen: conversations multi-agents
- CrewAI: Ã©quipes collaboratives
- Semantic Kernel: approche Microsoft

## 4. Tendances 2024
- Agents autonomes
- MultimodalitÃ© (texte + image + audio)
- IA gÃ©nÃ©rative personnalisÃ©e
- IntÃ©gration enterprise
""",
                "langchain_tutorial.txt": """
# LangChain Tutorial Complet

## Qu'est-ce que LangChain?
LangChain est un framework pour dÃ©velopper des applications avec des LLMs.

## Concepts ClÃ©s
1. **Chains**: SÃ©quences d'appels aux LLMs
2. **Agents**: EntitÃ©s qui utilisent des outils
3. **Memory**: Maintien du contexte
4. **Retrieval**: RAG et recherche d'informations

## RAG (Retrieval-Augmented Generation)
Le RAG combine:
- Base de connaissances (documents)
- Recherche sÃ©mantique (embeddings)
- GÃ©nÃ©ration de rÃ©ponses (LLM)

## LangGraph
Extension pour workflows complexes:
- Ã‰tats partagÃ©s
- Routage conditionnel
- Workflows cycliques
- Checkpointing
""",
                "business_case.txt": """
# Business Case: IA en Entreprise

## Contexte
Les entreprises adoptent massivement l'IA pour:
- RÃ©duire les coÃ»ts opÃ©rationnels
- AmÃ©liorer l'expÃ©rience client
- AccÃ©lÃ©rer l'innovation

## ROI de l'IA
Ã‰tudes montrent un ROI moyen de 300% sur 3 ans:
- 40% rÃ©duction temps traitement
- 60% amÃ©lioration satisfaction client
- 25% augmentation revenus

## Cas d'Usage Prioritaires
1. **Support Client**: Chatbots intelligents
2. **Analyse Documents**: Extraction automatique
3. **Veille Concurrentielle**: Monitoring automatisÃ©
4. **GÃ©nÃ©ration Contenu**: Marketing personnalisÃ©

## DÃ©fis Implementation
- Formation des Ã©quipes
- IntÃ©gration systÃ¨mes existants
- Gouvernance des donnÃ©es
- Changement culturel
"""
            }
            
            for filename, content in sample_docs.items():
                (docs_dir / filename).write_text(content, encoding='utf-8')
            
            print(f"ğŸ“„ {len(sample_docs)} documents d'exemple crÃ©Ã©s dans ./documents/")
        
        return docs_dir
    
    def ingest_documents(self, docs_path: str = "./documents"):
        """
        TODO 7: ImplÃ©menter l'ingestion de documents
        ğŸ’¡ APPRENTISSAGE: Pipeline de traitement de documents pour RAG
        
        Ã‰tapes Ã  implÃ©menter:
        1. Charger les documents (PDF, TXT)
        2. DÃ©couper en chunks intelligents
        3. CrÃ©er les embeddings
        4. Stocker dans la base vectorielle
        
        Concepts clÃ©s:
        - DocumentLoaders: PyPDFLoader, TextLoader
        - TextSplitter: RecursiveCharacterTextSplitter
        - VectorStore: Chroma
        - Embeddings: OpenAIEmbeddings
        """
        print(f"\nğŸ“š Ã‰TAPE: Ingestion des documents depuis {docs_path}")
        print("=" * 60)
        
        # TODO: ImplÃ©menter votre pipeline d'ingestion
        # 1. Charger les documents
        # 2. DÃ©couper en chunks
        # 3. CrÃ©er embeddings
        # 4. Stocker dans Chroma
        
        # Exemple de structure:
        # documents = []
        # for file_path in Path(docs_path).rglob("*"):
        #     if file_path.suffix.lower() in ['.pdf', '.txt']:
        #         # Charger le document
        #         # documents.extend(loaded_docs)
        
        # text_splitter = RecursiveCharacterTextSplitter(...)
        # splits = text_splitter.split_documents(documents)
        
        # self.vectorstore = Chroma.from_documents(...)
        
        print("âœ… TODO 7: ImplÃ©mentez l'ingestion de documents")
        return False  # Changer en True quand implÃ©mentÃ©
    
    def create_rag_chain(self):
        """
        TODO 8: CrÃ©er la chaÃ®ne RAG
        ğŸ’¡ APPRENTISSAGE: ChaÃ®nes LangChain et templates de prompts
        
        Concepts:
        - PromptTemplate avec variables
        - RetrievalQA chain
        - Retriever configuration
        - Custom prompts pour votre domaine
        """
        print("\nğŸ”— Ã‰TAPE: CrÃ©ation de la chaÃ®ne RAG")
        print("=" * 60)
        
        # TODO: CrÃ©er votre template de prompt personnalisÃ©
        # template = """
        # Utilisez le contexte suivant pour rÃ©pondre Ã  la question.
        # Si l'information n'est pas dans le contexte, dites-le clairement.
        # 
        # Contexte: {context}
        # Question: {question}
        # 
        # RÃ©ponse dÃ©taillÃ©e:
        # """
        
        # TODO: Configurer le retriever
        # retriever = self.vectorstore.as_retriever(...)
        
        # TODO: CrÃ©er la chaÃ®ne RetrievalQA
        # self.qa_chain = RetrievalQA.from_chain_type(...)
        
        print("âœ… TODO 8: ImplÃ©mentez la chaÃ®ne RAG")
        return False
    
    def create_langgraph_workflow(self):
        """
        TODO 9: CrÃ©er le workflow LangGraph
        ğŸ’¡ APPRENTISSAGE: Workflows stateful et routage conditionnel
        
        Architecture du workflow:
        Input â†’ Analyze â†’ Route â†’ [Simple/Complex] â†’ Output
        
        Concepts:
        - StateGraph: graphe d'Ã©tats
        - Nodes: fonctions de traitement
        - Edges: transitions entre nÅ“uds
        - Conditional routing: routage intelligent
        """
        print("\nğŸ”„ Ã‰TAPE: CrÃ©ation du workflow LangGraph")
        print("=" * 60)
        
        # TODO: DÃ©finir les fonctions de nÅ“uds
        def analyze_query(state: RAGWorkflowState) -> RAGWorkflowState:
            """Analyser la complexitÃ© de la requÃªte"""
            # ImplÃ©menter l'analyse de la requÃªte
            pass
        
        def simple_response(state: RAGWorkflowState) -> RAGWorkflowState:
            """RÃ©ponse simple et directe"""
            # ImplÃ©menter la logique de rÃ©ponse simple
            pass
        
        def complex_response(state: RAGWorkflowState) -> RAGWorkflowState:
            """RÃ©ponse complexe avec recherche approfondie"""
            # ImplÃ©menter la logique de rÃ©ponse complexe
            pass
        
        def decide_route(state: RAGWorkflowState) -> str:
            """DÃ©cider du chemin Ã  suivre"""
            # ImplÃ©menter la logique de routage
            return "simple"  # ou "complex"
        
        # TODO: Construire le graphe
        # workflow = StateGraph(RAGWorkflowState)
        # workflow.add_node("analyze", analyze_query)
        # workflow.add_node("simple", simple_response)
        # workflow.add_node("complex", complex_response)
        # workflow.set_entry_point("analyze")
        # workflow.add_conditional_edges("analyze", decide_route, {...})
        # workflow.add_edge("simple", END)
        # workflow.add_edge("complex", END)
        
        # self.workflow = workflow.compile()
        
        print("âœ… TODO 9: ImplÃ©mentez le workflow LangGraph")
        return False
    
    def add_monitoring(self):
        """
        TODO 10: Ajouter le monitoring
        ğŸ’¡ APPRENTISSAGE: ObservabilitÃ© et mÃ©triques en production
        
        MÃ©triques Ã  tracker:
        - Temps de rÃ©ponse
        - Scores de pertinence
        - Utilisation des tokens
        - Taux d'erreur
        - CoÃ»ts estimÃ©s
        """
        print("\nğŸ“Š Ã‰TAPE: Configuration du monitoring")
        print("=" * 60)
        
        # TODO: ImplÃ©menter la collecte de mÃ©triques
        # - Callbacks LangChain pour tracking
        # - Calcul des coÃ»ts
        # - Logs structurÃ©s
        # - Dashboard simple
        
        print("âœ… TODO 10: ImplÃ©mentez le monitoring")
        return False
    
    def query(self, question: str, use_workflow: bool = True) -> Dict[str, Any]:
        """
        TODO 11: ImplÃ©menter la fonction de requÃªte principale
        ğŸ’¡ APPRENTISSAGE: IntÃ©gration de tous les composants
        
        Cette fonction doit:
        1. Valider l'entrÃ©e
        2. ExÃ©cuter via workflow ou chaÃ®ne simple
        3. Collecter les mÃ©triques
        4. Retourner le rÃ©sultat structurÃ©
        """
        print(f"\nâ“ REQUÃŠTE: {question}")
        print("=" * 60)
        
        start_time = datetime.now()
        
        # TODO: ImplÃ©menter la logique de requÃªte
        # if use_workflow and self.workflow:
        #     # Utiliser LangGraph workflow
        #     result = self.workflow.invoke({"question": question})
        # elif self.qa_chain:
        #     # Utiliser chaÃ®ne RAG simple
        #     result = self.qa_chain.invoke({"query": question})
        # else:
        #     return {"error": "SystÃ¨me non initialisÃ©"}
        
        # Calculer les mÃ©triques
        execution_time = (datetime.now() - start_time).total_seconds()
        
        # TODO: Structurer la rÃ©ponse
        response = {
            "question": question,
            "answer": "TODO: ImplÃ©menter la gÃ©nÃ©ration de rÃ©ponse",
            "sources": [],
            "execution_time": execution_time,
            "workflow_used": use_workflow,
            "timestamp": start_time.isoformat()
        }
        
        print("âœ… TODO 11: ImplÃ©mentez la fonction de requÃªte")
        return response
    
    def run_demo(self):
        """
        TODO 12: CrÃ©er une dÃ©monstration complÃ¨te
        ğŸ’¡ APPRENTISSAGE: Test end-to-end du systÃ¨me
        """
        print("\nğŸ¬ DÃ‰MONSTRATION DE VOTRE SYSTÃˆME RAG")
        print("=" * 60)
        
        # Questions de test
        demo_questions = [
            "Qu'est-ce que LangChain et comment Ã§a fonctionne?",
            "Quels sont les avantages business de l'IA en entreprise?",
            "Comment implÃ©menter un systÃ¨me RAG?",
            "Quelles sont les tendances IA pour 2024?",
            "Quelle est la diffÃ©rence entre LangChain et LangGraph?"
        ]
        
        print("ğŸ¯ Questions de dÃ©monstration:")
        for i, q in enumerate(demo_questions, 1):
            print(f"  {i}. {q}")
        
        # TODO: ExÃ©cuter les questions et afficher les rÃ©sultats
        # for question in demo_questions:
        #     result = self.query(question)
        #     print(f"\nğŸ’¡ {question}")
        #     print(f"ğŸ“ {result['answer']}")
        #     print(f"â±ï¸ Temps: {result['execution_time']:.2f}s")
        
        print("\nâœ… TODO 12: ImplÃ©mentez la dÃ©monstration")
    
    def save_metrics(self):
        """
        TODO 13: Sauvegarder les mÃ©triques
        ğŸ’¡ APPRENTISSAGE: Persistance des donnÃ©es de monitoring
        """
        # TODO: Sauvegarder dans metrics.json
        pass

def main():
    """
    ğŸ¯ FONCTION PRINCIPALE - VOTRE PARCOURS D'APPRENTISSAGE
    
    Suivez cette progression pour maÃ®triser LangChain/LangGraph:
    """
    print("ğŸš€ BIENVENUE DANS VOTRE PROJET RAG SYSTEM !")
    print("=" * 60)
    print("ğŸ“š Vous allez apprendre en construisant un systÃ¨me complet")
    print("ğŸ¯ Objectif: SystÃ¨me RAG production-ready avec monitoring")
    print("â±ï¸ Temps estimÃ©: 45 minutes")
    print("\nğŸ“‹ PROGRESSION:")
    print("  1. âœ… Configuration de base")
    print("  2. ğŸ“„ Ingestion de documents")
    print("  3. ğŸ”— ChaÃ®ne RAG")
    print("  4. ğŸ”„ Workflow LangGraph")
    print("  5. ğŸ“Š Monitoring")
    print("  6. ğŸ¬ DÃ©monstration")
    
    try:
        # Initialiser le systÃ¨me
        rag_system = MyRAGSystem()
        
        # Ã‰tape 1: PrÃ©parer les documents
        rag_system.create_documents_folder()
        
        # Ã‰tape 2: Message d'encouragement
        print("\nğŸ“ PRÃŠT Ã€ COMMENCER ?")
        print("ğŸ‘† Suivez les TODO dans le code pour apprendre !")
        print("ğŸ’¡ Chaque TODO vous enseigne un concept important")
        
        # TODO: DÃ©commenter quand vous avez implÃ©mentÃ© les mÃ©thodes
        # rag_system.ingest_documents()
        # rag_system.create_rag_chain()
        # rag_system.create_langgraph_workflow()
        # rag_system.add_monitoring()
        # rag_system.run_demo()
        # rag_system.save_metrics()
        
        print("\nğŸ† Quand vous aurez terminÃ© tous les TODO:")
        print("   - Vous maÃ®triserez LangChain/LangGraph")
        print("   - Vous aurez un systÃ¨me RAG production-ready")
        print("   - Vous comprendrez le monitoring IA")
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        print("ğŸ’¡ VÃ©rifiez votre configuration (clÃ© API, dÃ©pendances)")

if __name__ == "__main__":
    main()