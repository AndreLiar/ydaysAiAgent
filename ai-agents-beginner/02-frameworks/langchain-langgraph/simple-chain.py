#!/usr/bin/env python3
"""
LangChain - Cha√Ænes Simples et RAG Pipeline
D√©monstration des patterns LangChain pour agents IA
"""

import os
from typing import Dict, List, Any
from dotenv import load_dotenv

# Dependencies: pip install langchain langchain-openai langchain-community chromadb
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.schema import Document
from langchain.chains import RetrievalQA
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.memory import ConversationBufferMemory

load_dotenv()

class LangChainDemo:
    """D√©monstration des capacit√©s LangChain essentielles"""
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model="gpt-4",
            temperature=0.7,
            max_tokens=500
        )
        self.embeddings = OpenAIEmbeddings()
        
        print("ü¶ú LangChain Demo initialis√© avec GPT-4")
    
    def demo_simple_chain(self):
        """D√©monstration d'une cha√Æne LLM simple"""
        print("\nüìã DEMO 1: Cha√Æne Simple avec Prompt Template")
        print("=" * 50)
        
        # Template de prompt structur√©
        template = """
        Tu es un expert en {domain} avec 10 ans d'exp√©rience.
        
        Question: {question}
        
        R√©ponds de mani√®re:
        1. Pr√©cise et technique
        2. Avec des exemples concrets
        3. En mentionnant les bonnes pratiques
        
        R√©ponse:
        """
        
        prompt = PromptTemplate(
            input_variables=["domain", "question"],
            template=template
        )
        
        # Cr√©er la cha√Æne
        chain = LLMChain(
            llm=self.llm,
            prompt=prompt,
            verbose=True  # Voir les √©tapes
        )
        
        # Tests avec diff√©rents domaines
        test_cases = [
            {
                "domain": "d√©veloppement d'agents IA",
                "question": "Comment structurer une √©quipe d'agents collaboratifs?"
            },
            {
                "domain": "cybers√©curit√©",  
                "question": "Quelles sont les vuln√©rabilit√©s des agents IA?"
            }
        ]
        
        for i, test in enumerate(test_cases, 1):
            print(f"\nüß™ Test {i}: {test['domain']}")
            print(f"‚ùì Question: {test['question']}")
            
            response = chain.run(
                domain=test['domain'],
                question=test['question']
            )
            
            print(f"üéØ R√©ponse: {response[:200]}...")
            print("-" * 30)
    
    def demo_rag_pipeline(self):
        """D√©monstration RAG (Retrieval-Augmented Generation)"""
        print("\nüîç DEMO 2: Pipeline RAG Complet")
        print("=" * 50)
        
        # 1. Cr√©er des documents de d√©monstration
        documents = [
            Document(
                page_content="""
                LangChain est un framework pour d√©velopper des applications aliment√©es par des mod√®les de langage.
                Il fournit des abstractions et des outils pour cr√©er des cha√Ænes complexes d'appels LLM,
                int√©grer des sources de donn√©es externes, et g√©rer la m√©moire conversationnelle.
                Les composants principaux incluent: Prompts, LLMs, Chains, Agents, et Memory.
                """,
                metadata={"source": "langchain_docs", "topic": "overview"}
            ),
            Document(
                page_content="""
                Les agents LangChain peuvent utiliser des outils pour interagir avec le monde ext√©rieur.
                Ils suivent le pattern ReAct (Reasoning + Acting): observer, r√©fl√©chir, agir, r√©p√©ter.
                Les agents peuvent utiliser des calculatrices, rechercher sur le web, acc√©der √† des APIs,
                ou ex√©cuter du code Python. L'agent d√©cide quels outils utiliser selon le contexte.
                """,
                metadata={"source": "langchain_docs", "topic": "agents"}
            ),
            Document(
                page_content="""
                LangGraph est une extension de LangChain pour cr√©er des workflows d'agents avec √©tats.
                Il permet de d√©finir des graphes de conversation o√π les agents peuvent passer 
                d'un √©tat √† l'autre selon les r√©sultats. Id√©al pour les workflows complexes
                n√©cessitant des points de d√©cision, des boucles, ou des validations.
                """,
                metadata={"source": "langchain_docs", "topic": "langgraph"}
            ),
            Document(
                page_content="""
                CrewAI permet de cr√©er des √©quipes d'agents sp√©cialis√©s qui collaborent.
                Chaque agent a un r√¥le, des objectifs, et des outils sp√©cifiques.
                L'orchestrateur coordonne les t√¢ches entre agents selon leurs comp√©tences.
                Parfait pour des projets n√©cessitant plusieurs expertise: recherche, analyse, √©criture.
                """,
                metadata={"source": "frameworks_comparison", "topic": "crewai"}
            )
        ]
        
        # 2. D√©couper les documents
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=300,
            chunk_overlap=50
        )
        
        split_docs = text_splitter.split_documents(documents)
        print(f"üìÑ Documents d√©coup√©s: {len(split_docs)} chunks")
        
        # 3. Cr√©er le vector store
        vectorstore = Chroma.from_documents(
            documents=split_docs,
            embedding=self.embeddings,
            persist_directory="./langchain_demo_db"
        )
        
        print("üóÇÔ∏è Base vectorielle cr√©√©e")
        
        # 4. Cr√©er le syst√®me RAG
        retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
        
        rag_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=retriever,
            return_source_documents=True,
            verbose=True
        )
        
        # 5. Tester le RAG
        questions = [
            "Quels sont les composants principaux de LangChain?",
            "Comment fonctionnent les agents avec des outils?", 
            "Quelle est la diff√©rence entre LangChain et CrewAI?",
            "Comment LangGraph g√®re-t-il les workflows complexes?"
        ]
        
        for i, question in enumerate(questions, 1):
            print(f"\n‚ùì Question {i}: {question}")
            
            result = rag_chain({"query": question})
            
            print(f"üéØ R√©ponse: {result['result'][:200]}...")
            
            # Afficher les sources
            sources = [doc.metadata.get('source', 'Unknown') for doc in result['source_documents']]
            print(f"üìö Sources: {', '.join(set(sources))}")
            print("-" * 40)
    
    def demo_memory_chain(self):
        """D√©monstration des cha√Ænes avec m√©moire"""
        print("\nüß† DEMO 3: Cha√Ænes avec M√©moire Conversationnelle")
        print("=" * 50)
        
        # Cr√©er une m√©moire conversationnelle
        memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True
        )
        
        # Template avec contexte de conversation
        template = """
        Tu es un assistant sp√©cialis√© en agents IA. Tu maintiens une conversation coh√©rente
        en gardant en m√©moire ce qui a √©t√© dit pr√©c√©demment.
        
        Historique de conversation:
        {chat_history}
        
        Question actuelle: {question}
        
        R√©ponse (coh√©rente avec l'historique):
        """
        
        prompt = PromptTemplate(
            input_variables=["chat_history", "question"],
            template=template
        )
        
        # Cha√Æne avec m√©moire
        conversation_chain = LLMChain(
            llm=self.llm,
            prompt=prompt,
            memory=memory,
            verbose=True
        )
        
        # Conversation simul√©e
        conversation = [
            "Qu'est-ce qu'un agent IA?",
            "Peux-tu me donner des exemples concrets?",
            "Comment impl√©menter le pattern dont tu viens de parler?",
            "Quels sont les risques de cette approche?"
        ]
        
        for i, question in enumerate(conversation, 1):
            print(f"\nüë§ Utilisateur {i}: {question}")
            
            response = conversation_chain.run(question=question)
            
            print(f"ü§ñ Assistant: {response[:300]}...")
            print("-" * 40)
        
        # Afficher l'historique final
        print("\nüìö Historique de la conversation:")
        print(memory.buffer)
    
    def cleanup(self):
        """Nettoyer les ressources temporaires"""
        import shutil
        try:
            shutil.rmtree("./langchain_demo_db")
            print("üóëÔ∏è Base vectorielle temporaire supprim√©e")
        except:
            pass


def main():
    """D√©monstration compl√®te LangChain"""
    
    print("ü¶ú LangChain Framework Demo")
    print("=" * 60)
    
    # V√©rifier les pr√©requis
    if not os.getenv("OPENAI_API_KEY"):
        print("‚ö†Ô∏è  OPENAI_API_KEY manquante!")
        print("   Ajoutez votre cl√© dans le fichier .env")
        return
    
    # Initialiser et lancer les demos
    demo = LangChainDemo()
    
    try:
        # Demo 1: Cha√Ænes simples
        demo.demo_simple_chain()
        
        # Demo 2: RAG Pipeline
        demo.demo_rag_pipeline()
        
        # Demo 3: M√©moire conversationnelle
        demo.demo_memory_chain()
        
        print(f"\nüéâ Toutes les d√©mos LangChain termin√©es!")
        print(f"\nüí° Points cl√©s √† retenir:")
        print(f"   ‚úÖ Templates de prompts pour la coh√©rence")
        print(f"   ‚úÖ RAG pour int√©grer vos donn√©es priv√©es")
        print(f"   ‚úÖ M√©moire conversationnelle pour le contexte")
        print(f"   ‚úÖ Cha√Ænes composables pour la complexit√©")
        
    except Exception as e:
        print(f"‚ùå Erreur pendant la d√©mo: {e}")
    
    finally:
        demo.cleanup()


if __name__ == "__main__":
    main()